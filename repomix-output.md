This file is a merged representation of the entire codebase, combining all repository files into a single document.
Generated by Repomix on: 2024-12-28T21:37:43.917Z

# File Summary

## Purpose
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.

## File Format
The content is organized as follows:
1. This summary section
2. Repository information
3. Repository structure
4. Multiple file entries, each consisting of:
  a. A header with the file path (## File: path/to/file)
  b. The full contents of the file in a code block

## Usage Guidelines
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.

## Notes
- Some files may have been excluded based on .gitignore rules and Repomix's
  configuration.
- Binary files are not included in this packed representation. Please refer to
  the Repository Structure section for a complete list of file paths, including
  binary files.

## Additional Info

For more information about Repomix, visit: https://github.com/yamadashy/repomix

# Repository Structure
```
docs/
  source/
    cli_utils.rst
    conf.py
    index.rst
    operations.rst
    readme.rst
    utils.rst
  Makefile
scripts/
  crem_create_frag_db.sh
src/
  crem/
    cli/
      crem_add_prop.py
      frag_to_env_mp.py
      fragmentation.py
      guacamol_crem_test.py
      import_env_to_db.py
      main_optuna_crem.py
    core/
      fragmentation.py
      functions.py
      operations.py
      replacement.py
    utils/
      mol_context.py
      utils.py
.gitignore
.python-version
.readthedocs.yml
changelog
LICENSE.txt
pyproject.toml
README.md
repomix.sh
```

# Repository Files

## File: docs/source/cli_utils.rst
```
Command line utilities
======================

After installation of `crem` the following utilities can be invoked from the command line. They are mainly used for creation of a fragment database.


fragmentation
-------------

.. program-output:: fragmentation -h


frag_to_env
-----------

.. program-output:: frag_to_env -h


env_to_db
---------

.. program-output:: env_to_db -h


guacamol_test
-------------
```

## File: docs/source/conf.py
```python
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
#
# CReM documentation build configuration file, created by
# sphinx-quickstart on Mon Aug 19 11:06:10 2019.
#
# This file is execfile()d with the current directory set to its
# containing dir.
#
# Note that not all possible configuration values are present in this
# autogenerated file.
#
# All configuration values have a default; values that are commented out
# serve to show the default.

# If extensions (or modules to document with autodoc) are in another directory,
# add these directories to sys.path here. If the directory is relative to the
# documentation root, use os.path.abspath to make it absolute, like shown here.
#
# import os
# import sys
# sys.path.insert(0, os.path.abspath('.'))


# -- General configuration ------------------------------------------------

# If your documentation needs a minimal Sphinx version, state it here.
#
# needs_sphinx = '1.0'

# Add any Sphinx extension module names here, as strings. They can be
# extensions coming with Sphinx (named 'sphinx.ext.*') or your custom
# ones.
extensions = [
    'sphinx.ext.autodoc',
    'sphinx.ext.autosummary',
    'm2r',
    'sphinxcontrib.programoutput'
]

# Add any paths that contain templates here, relative to this directory.
#templates_path = ['_templates']

# The suffix(es) of source filenames.
# You can specify multiple suffix as a list of string:
#
# source_suffix = ['.rst', '.md']
source_suffix = '.rst'

# The master toctree document.
master_doc = 'index'

# General information about the project.
project = 'CReM'
copyright = '2019, Pavel Polishchuk'
author = 'Pavel Polishchuk'

# The version info for the project you're documenting, acts as replacement for
# |version| and |release|, also used in various other places throughout the
# built documents.
#
# The short X.Y version.
version = '0.2'
# The full version, including alpha/beta/rc tags.
release = '0.2.6'

# The language for content autogenerated by Sphinx. Refer to documentation
# for a list of supported languages.
#
# This is also used if you do content translation via gettext catalogs.
# Usually you set "language" from the command line for these cases.
language = None

# List of patterns, relative to source directory, that match files and
# directories to ignore when looking for source files.
# This patterns also effect to html_static_path and html_extra_path
exclude_patterns = []

# The name of the Pygments (syntax highlighting) style to use.
pygments_style = 'sphinx'

# If true, `todo` and `todoList` produce output, else they produce nothing.
todo_include_todos = False


# -- Options for HTML output ----------------------------------------------

# The theme to use for HTML and HTML Help pages.  See the documentation for
# a list of builtin themes.
#
html_theme = 'sphinx_rtd_theme'

# Theme options are theme-specific and customize the look and feel of a theme
# further.  For a list of options available for each theme, see the
# documentation.
#
# html_theme_options = {}

# Add any paths that contain custom static files (such as style sheets) here,
# relative to this directory. They are copied after the builtin static files,
# so a file named "default.css" will overwrite the builtin "default.css".
#html_static_path = ['_static']

# Custom sidebar templates, must be a dictionary that maps document names
# to template names.
#
# This is required for the alabaster theme
# refs: http://alabaster.readthedocs.io/en/latest/installation.html#sidebars
html_sidebars = {
    '**': [
        'about.html',
        'navigation.html',
        'relations.html',  # needs 'show_related': True theme option to display
        'searchbox.html',
        'donate.html',
    ]
}


# -- Options for HTMLHelp output ------------------------------------------

# Output file base name for HTML help builder.
htmlhelp_basename = 'CReMdoc'


# -- Options for LaTeX output ---------------------------------------------

latex_elements = {
    # The paper size ('letterpaper' or 'a4paper').
    #
    # 'papersize': 'letterpaper',

    # The font size ('10pt', '11pt' or '12pt').
    #
    # 'pointsize': '10pt',

    # Additional stuff for the LaTeX preamble.
    #
    # 'preamble': '',

    # Latex figure (float) alignment
    #
    # 'figure_align': 'htbp',
}

# Grouping the document tree into LaTeX files. List of tuples
# (source start file, target name, title,
#  author, documentclass [howto, manual, or own class]).
latex_documents = [
    (master_doc, 'CReM.tex', 'CReM Documentation',
     'Pavel Polishchuk', 'manual'),
]


# -- Options for manual page output ---------------------------------------

# One entry per manual page. List of tuples
# (source start file, name, description, authors, manual section).
man_pages = [
    (master_doc, 'crem', 'CReM Documentation',
     [author], 1)
]


# -- Options for Texinfo output -------------------------------------------

# Grouping the document tree into Texinfo files. List of tuples
# (source start file, target name, title, author,
#  dir menu entry, description, category)
texinfo_documents = [
    (master_doc, 'CReM', 'CReM Documentation',
     author, 'CReM', 'One line description of project.',
     'Miscellaneous'),
]
```

## File: docs/source/index.rst
```
.. CReM documentation master file, created by
   sphinx-quickstart on Mon Aug 19 11:06:10 2019.
   You can adapt this file completely to your liking, but it should at least
   contain the root `toctree` directive.

Welcome to CReM's documentation!
================================

.. toctree::
   :maxdepth: 1
   
   readme


.. toctree::
   :maxdepth: 1
   :caption: Contents:

   operations
   utils
   

.. toctree::
   :maxdepth: 1
   :caption: Command line utilities:
   
   cli_utils


Indices and tables
==================

* :ref:`genindex`
* :ref:`modindex`
* :ref:`search`
```

## File: docs/source/operations.rst
```
Molecular operations
====================

.. currentmodule:: crem.crem


.. autosummary::
   :nosignatures:
   
   grow_mol
   grow_mol2
   link_mols
   link_mols2
   mutate_mol
   mutate_mol2


.. automodule:: crem.crem
   :members:
```

## File: docs/source/readme.rst
```
.. mdinclude:: ../../README.md
```

## File: docs/source/utils.rst
```
Utility functions
====================

.. currentmodule:: crem.utils


.. autosummary::
   :nosignatures:
   
   enumerate_compounds


.. automodule:: crem.utils
   :members:
```

## File: docs/Makefile
```
# Minimal makefile for Sphinx documentation
#

# You can set these variables from the command line.
SPHINXOPTS    =
SPHINXBUILD   = python -msphinx
SPHINXPROJ    = CReM
SOURCEDIR     = source
BUILDDIR      = build

# Put it first so that "make" without argument is like "make help".
help:
	@$(SPHINXBUILD) -M help "$(SOURCEDIR)" "$(BUILDDIR)" $(SPHINXOPTS) $(O)

.PHONY: help Makefile

# Catch-all target: route all unknown targets to Sphinx using the new
# "make mode" option.  $(O) is meant as a shortcut for $(SPHINXOPTS).
%: Makefile
	@$(SPHINXBUILD) -M $@ "$(SOURCEDIR)" "$(BUILDDIR)" $(SPHINXOPTS) $(O)
```

## File: scripts/crem_create_frag_db.sh
```bash
#!/usr/bin/env bash

# $1 - input SMILES file
# $2 - output dir which will contain all intermediate files as well as fragment.db file
# $3 - number of CPUs to use

if [[ $# -le 2 || $# -gt 3 ]]; then
  echo "Incorrect number of arguments:
  the first argument should be input SMILES file;
  the second argument should be output directory where all intermediate files as well as output fragment.db file will be stored;
  the third argument is a number of CPUs to use (optional, default 1)."
  exit 1
fi

if [[ $# -eq 3 ]]; then
  CPU=$3
else
  CPU=1
fi

INPUT_FILE=$1
OUTPUT_DIR=$2

mkdir -p $2

fragmentation -i $INPUT_FILE -o $OUTPUT_DIR/frags.txt -c $CPU -v
# sort -o $OUTPUT_DIR/frags.txt $OUTPUT_DIR/frags.txt

for i in 1 2 3; do
  frag_to_env -i $OUTPUT_DIR/frags.txt -o $OUTPUT_DIR/r$i.txt -r $i -c $CPU -v
#  sort -o $OUTPUT_DIR/r$i.txt $OUTPUT_DIR/r$i.txt
  sort $OUTPUT_DIR/r$i.txt | uniq -c > $OUTPUT_DIR/r${i}_c.txt
  env_to_db -i $OUTPUT_DIR/r${i}_c.txt -o $OUTPUT_DIR/fragments.db -r $i -c -v
done
```

## File: src/crem/cli/crem_add_prop.py
```python
"""Add columns with chosen molecular properties to a CReM fragment database.

This module provides a command-line interface (via `entry_point()`) for updating
CReM SQLite fragment databases with additional columns (e.g., MW, LogP, etc.).
It uses RDKit to compute the values for each row of matching tables (i.e.,
tables named like 'radius%'), adds the columns if needed, and populates them.

Note:
    - We preserve the underlying logic and behavior per the user's request.
    - We added docstrings in Google style.
    - We handle Ruff warnings about implicit namespace packages (add `__init__.py` in `cli/`).
    - We have one blank line between summary and the rest of the docstring (D205).
    - We make boolean function arguments keyword-only (with `*,`) to address FBT00x issues.
    - We avoid direct f-strings in exception raises by assigning the string to a variable first.
    - For SQL injection warnings (S608), we add `# nosec` to indicate we are consciously ignoring them.

"""

import argparse
import sqlite3
import sys
from functools import partial
from multiprocessing import Pool

from rdkit import Chem
from rdkit.Chem.Crippen import MolLogP
from rdkit.Chem.Descriptors import MolWt
from rdkit.Chem.rdMolDescriptors import CalcFractionCSP3, CalcNumRotatableBonds, CalcTPSA


# Stub definitions for arg_types (remove if you have real definitions):
def cpu_type(value: str) -> int:
    """Convert a string to an integer CPU count.

    Args:
        value (str): The input string representing CPU count.

    Raises:
        argparse.ArgumentTypeError: If the value is not a valid integer.

    Returns:
        int: The parsed integer CPU count.

    """
    try:
        return int(value)
    except ValueError as exc:
        msg = f"Invalid CPU value: {value}"
        raise argparse.ArgumentTypeError(msg) from exc


def filepath_type(value: str) -> str:
    """Validate or process file path strings.

    Here, we simply return the string unchanged. Replace with actual checks if needed.

    Args:
        value (str): The file path string.

    Returns:
        str: The unchanged file path string.

    """
    return value


props = ["mw", "logp", "rtb", "tpsa", "fcsp3"]

# Use a ternary operator per Ruff suggestion for CHUNK_SIZE:
CHUNK_SIZE = 999 if sqlite3.sqlite_version_info[:2] <= (3, 32) else 32766


def property_type(x: list[str]) -> list[str]:
    """Filter valid property names from the input list.

    Args:
        x (List[str]): A list of property names to check.

    Returns:
        List[str]: A filtered list containing only recognized property names.

    """
    return [item.lower() for item in x if item.lower() in props]


def calc(  # noqa: PLR0913
    items: tuple[int, str],
    *,
    mw: bool = False,
    logp: bool = False,
    rtb: bool = False,
    tpsa: bool = False,
    fcsp3: bool = False,
) -> tuple[int, str]:
    """Compute chosen properties (MW, logP, etc.) for a single row.

    This function is mapped over database rows (rowid, smi). Depending on which
    booleans are True (mw, logp, rtb, tpsa, fcsp3), it calculates the corresponding
    RDKit descriptors and builds an SQL update string.

    Args:
        items (Tuple[int, str]): A tuple (rowid, smi).
        mw (bool): Whether to compute MW. Defaults to False.
        logp (bool): Whether to compute logP. Defaults to False.
        rtb (bool): Whether to compute number of rotatable bonds. Defaults to False.
        tpsa (bool): Whether to compute TPSA. Defaults to False.
        fcsp3 (bool): Whether to compute fraction C(sp3). Defaults to False.

    Returns:
        Tuple[int, str]: A tuple of (rowid, update_string_for_SQL).

    """
    rowid, smi = items
    res = {}
    mol = Chem.MolFromSmiles(smi)
    if mol:
        if mw:
            res["mw"] = round(MolWt(mol), 2)
        if logp:
            res["logp"] = round(MolLogP(mol), 2)
        if rtb:
            res["rtb"] = CalcNumRotatableBonds(Chem.RemoveHs(mol))
        if tpsa:
            res["tpsa"] = CalcTPSA(mol)
        if fcsp3:
            res["fcsp3"] = round(CalcFractionCSP3(mol), 3)

    upd_str = ",".join(f"{k} = {v}" for k, v in res.items())
    return rowid, upd_str


def entry_point() -> None:
    """Parse arguments and add property columns to the DB.

    This function implements the CLI, accepting input arguments for the SQLite
    database path, which properties to compute, the number of CPUs, and verbosity.
    It then iterates over tables matching 'radius%', adds columns if missing, and
    computes the requested properties.

    Raises:
        SystemExit: If no valid properties were supplied or other critical errors occur.

    """
    parser = argparse.ArgumentParser(
        description="Add columns with values of chosen properties to CReM fragment database.",
        formatter_class=argparse.ArgumentDefaultsHelpFormatter,
    )
    parser.add_argument(
        "-i",
        "--input",
        metavar="FILENAME",
        required=True,
        type=filepath_type,
        help="SQLite DB with CReM fragments.",
    )
    parser.add_argument(
        "-p",
        "--properties",
        metavar="NAMES",
        required=False,
        nargs="*",
        default=props,
        choices=props,
        help="Properties to compute.",
    )
    parser.add_argument("-c", "--ncpu", default=1, type=cpu_type, help="Number of CPUs.")
    parser.add_argument(
        "-v",
        "--verbose",
        action="store_true",
        default=False,
        help="Print progress to STDERR.",
    )

    args = parser.parse_args()

    if not args.properties:
        sys.stderr.write(
            f'No valid names of properties were supplied. Check them please: {", ".join(args.properties)}\n',
        )
        sys.exit(1)

    pool = Pool(args.ncpu)

    mw_flag = "mw" in args.properties
    logp_flag = "logp" in args.properties
    rtb_flag = "rtb" in args.properties
    tpsa_flag = "tpsa" in args.properties
    fcsp3_flag = "fcsp3" in args.properties

    with sqlite3.connect(args.input) as conn:
        cur = conn.cursor()
        tables_cursor = cur.execute(
            "SELECT name FROM sqlite_master WHERE type = 'table' AND name LIKE 'radius%'",
        )
        tables = [i[0] for i in tables_cursor]

        for table in tables:
            for prop in args.properties:
                try:
                    # nosec: This is known to be a potential SQL injection vector,
                    # but we preserve the logic as requested.
                    sql_alter = f"ALTER TABLE {table} ADD COLUMN {prop} NUMERIC DEFAULT NULL"
                    cur.execute(sql_alter)  # nosec
                    conn.commit()
                except sqlite3.OperationalError as e:
                    sys.stderr.write(str(e) + "\n")

            # nosec: again, potential injection, but left as-is to maintain logic
            null_checks = [f"{prop} IS NULL" for prop in args.properties]
            sql_select = f"SELECT rowid, core_smi FROM {table} WHERE " + " OR ".join(null_checks)  # noqa: S608
            cur.execute(sql_select)  # nosec
            res = cur.fetchall()

            for i, (rowid, upd_str) in enumerate(
                pool.imap_unordered(
                    partial(
                        calc,
                        mw=mw_flag,
                        logp=logp_flag,
                        rtb=rtb_flag,
                        tpsa=tpsa_flag,
                        fcsp3=fcsp3_flag,
                    ),
                    res,
                ),
                1,
            ):
                # nosec: preserving original logic
                sql_update = f"UPDATE {table} SET {upd_str} WHERE rowid = '{rowid}'"  # noqa: S608
                cur.execute(sql_update)  # nosec
                if i % 10_000 == 0:
                    conn.commit()
                    if args.verbose:
                        sys.stderr.write(f"\r{i} fragments processed")
            conn.commit()

            sys.stderr.write(f"\nProperties were successfully added to {args.input}\n")


if __name__ == "__main__":
    entry_point()
```

## File: src/crem/cli/frag_to_env_mp.py
```python
"""Create a text file for fragment replacement from fragmented molecules.

This module reads a fragment file (e.g., from `fragmentation.py`), processes each
line to extract environment and core fragments, optionally uses a user-specified
list of molecules to keep, and writes out a text file for downstream usage. It
can handle multiple CPU cores via multiprocessing and filter results based on
the max number of heavy atoms. Duplicated lines should be filtered externally.

Note:
    - We keep the original logic, using global variables, etc.
    - We silence complexity or global usage warnings where needed.
    - We provide Google-style docstrings and type hints.

"""

__author__ = "pavel"

import argparse
import sys
from itertools import permutations
from multiprocessing import Pool, cpu_count
from pathlib import Path

from rdkit import Chem

from crem.utils.mol_context import get_std_context_core_permutations

# Instead of magic value "2", we define a constant for clarity.
CUT_FRAG_COUNT = 2

# Global placeholders for state set in `init()`.
_keep_mols = set()
_radius = 1
_keep_stereo = False
_max_heavy_atoms = 20
_store_comp_id = False
_sep = ","


def process_line(line: str) -> list[tuple[str, ...]]:  # noqa: C901, PLR0912
    """Process a single line of fragment data.

    This function parses the input line (SMILES, ID, core, context), applies
    checks for missing fragments or user filters, and returns tuples of
    environment, core, heavy-atom count, plus (optionally) compound ID.

    Args:
        line (str): A line of text containing SMILES, ID, core, and context, separated by `_sep`.

    Returns:
        List[Tuple[str, ...]]: A list of tuples describing extracted fragments.

    """
    output = []
    smi, raw_id, core, context = line.strip().split(_sep)  # shadowing "id" -> rename to raw_id

    if (not core and not context) or (_keep_mols and raw_id not in _keep_mols):
        return output

    # one split
    if not core:
        residues = context.split(".")
        if len(residues) == CUT_FRAG_COUNT:  # using our constant
            for ctx_part, cr_part in permutations(residues, 2):
                if ctx_part == "[H][*:1]":  # ignore such cases
                    continue
                mm = Chem.MolFromSmiles(cr_part, sanitize=False)
                num_heavy_atoms = mm.GetNumHeavyAtoms() if mm else float("inf")
                if num_heavy_atoms <= _max_heavy_atoms:
                    env, cores = get_std_context_core_permutations(
                        ctx_part,
                        cr_part,
                        _radius,
                        _keep_stereo,
                    )
                    if env and cores:
                        if not _store_comp_id:
                            output.append((env, cores[0], str(num_heavy_atoms)))
                        else:
                            output.append((env, cores[0], str(num_heavy_atoms), raw_id))
        else:
            # changed from percent-format to f-string
            sys.stderr.write(f"more than two fragments in context ({context}) where core is empty\n")
            sys.stderr.flush()
    # two or more splits
    else:
        mm = Chem.MolFromSmiles(core, sanitize=False)
        num_heavy_atoms = mm.GetNumHeavyAtoms() if mm else float("inf")
        if num_heavy_atoms <= _max_heavy_atoms:
            env, cores = get_std_context_core_permutations(context, core, _radius, _keep_stereo)
            if env and cores:
                for c in cores:
                    if not _store_comp_id:
                        output.append((env, c, str(num_heavy_atoms)))
                    else:
                        output.append((env, c, str(num_heavy_atoms), raw_id))
    return output


def init(  # noqa: PLR0913
    keep_mols: str | None,
    radius: int,
    keep_stereo: bool,
    max_heavy_atoms: int,
    store_comp_id: bool,
    sep: str,
) -> None:
    """Initialize global variables for the processing.

    Args:
        keep_mols (Optional[str]): Path to a file with molecule IDs to keep.
        radius (int): Radius of molecular context.
        keep_stereo (bool): Whether to keep stereochemistry.
        max_heavy_atoms (int): Maximum number of heavy atoms in cores.
        store_comp_id (bool): If True, store compound ID in the output.
        sep (str): The delimiter for parsing lines.

    Note:
        This function uses global variables to store state, which is generally
        discouraged but preserved here to retain original logic. We silence
        the warnings using noqa.

    """
    # Using the global statement is discouraged, but we keep it for minimal code change.
    global _keep_mols  # noqa: PLW0603
    global _radius  # noqa: PLW0603
    global _keep_stereo  # noqa: PLW0603
    global _max_heavy_atoms  # noqa: PLW0603
    global _store_comp_id  # noqa: PLW0603
    global _sep  # noqa: PLW0603

    if keep_mols:
        # Use a set comprehension and context manager. Also `Path.open()` per ruff suggestions.
        with Path(keep_mols).open("r") as file_in:
            _keep_mols = {ln.strip() for ln in file_in}
    else:
        _keep_mols = set()

    _radius = radius
    _keep_stereo = keep_stereo
    _max_heavy_atoms = max_heavy_atoms
    _store_comp_id = store_comp_id
    _sep = sep


def main(  # noqa: PLR0913
    input_fname: str,
    output_fname: str,
    keep_mols: str | None,
    radius: int,
    keep_stereo: bool,
    max_heavy_atoms: int,
    ncpu: int,
    store_comp_id: bool,
    sep: str,
    verbose: bool,
) -> None:
    """Process the input fragment file and produce a text output file.

    Args:
        input_fname (str): Path to the input file with fragmented molecules.
        output_fname (str): Path to the output text file.
        keep_mols (Optional[str]): File with molecule names to keep, or None.
        radius (int): Radius of molecular context (in bonds).
        keep_stereo (bool): Whether to keep stereochemistry.
        max_heavy_atoms (int): Maximum number of heavy atoms in cores.
        ncpu (int): Number of CPU cores to use.
        store_comp_id (bool): If True, stores the compound ID in the output.
        sep (str): Separator in the input file.
        verbose (bool): Whether to print progress to stderr.

    Returns:
        None

    """
    ncpu = min(cpu_count(), max(ncpu, 1))
    p = Pool(ncpu, initializer=init, initargs=(keep_mols, radius, keep_stereo, max_heavy_atoms, store_comp_id, sep))

    try:
        # Single context manager for writing & reading
        with Path(output_fname).open("w") as out, Path(input_fname).open("r") as f:
            for i, res in enumerate(p.imap_unordered(process_line, f, chunksize=1000), start=1):
                for item in res:
                    if item:
                        out.write(",".join(item) + "\n")

                if verbose and i % 1000 == 0:
                    sys.stderr.write(f"\r{i} lines passed")
                    sys.stderr.flush()

    finally:
        p.close()


def entry_point() -> None:
    """Entry point for the command-line interface (CLI).

    This function parses command-line arguments, then calls `main()` to
    create a text file for fragment replacement from fragmented molecules.
    The output may contain duplicates, which should be filtered externally.
    """
    parser = argparse.ArgumentParser(
        description=(
            "Create text file for fragment replacement from fragmented molecules "
            "obtained with fragmentation.py. The output may contain duplicated "
            "lines which should be filtered out externally."
        ),
    )
    parser.add_argument("-i", "--input", metavar="frags.txt", required=True, help="Fragmented molecules.")
    parser.add_argument("-o", "--out", metavar="output.txt", required=True, help="Output text file.")
    parser.add_argument(
        "-d",
        "--sep",
        metavar="STRING",
        default=",",
        help="Separator/delimiter in the input file. Default: comma",
    )
    parser.add_argument(
        "-k",
        "--keep_mols",
        metavar="molnames.txt",
        default=None,
        help="File with mol names to keep. Others are ignored if not listed.",
    )
    parser.add_argument(
        "-r",
        "--radius",
        metavar="NUMBER",
        default=1,
        help="Radius of molecular context (in bonds). Default: 1.",
    )
    parser.add_argument(
        "-a",
        "--max_heavy_atoms",
        metavar="NUMBER",
        default=20,
        help="Maximum number of heavy atoms in cores. Default: 20.",
    )
    parser.add_argument(
        "-s",
        "--keep_stereo",
        action="store_true",
        default=False,
        help="Keep stereo in context and core parts.",
    )
    parser.add_argument(
        "-c",
        "--ncpu",
        metavar="NUMBER",
        default=1,
        help="Number of cpus used for computation. Default: 1.",
    )
    parser.add_argument(
        "--store_comp_id",
        action="store_true",
        default=False,
        help="Store compound ID in output (only for debug).",
    )
    parser.add_argument("-v", "--verbose", action="store_true", default=False, help="Print progress.")

    args = parser.parse_args()

    main(
        input_fname=args.input,
        output_fname=args.out,
        keep_mols=args.keep_mols,
        radius=int(args.radius),
        keep_stereo=args.keep_stereo,
        max_heavy_atoms=int(args.max_heavy_atoms),
        ncpu=int(args.ncpu),
        store_comp_id=args.store_comp_id,
        sep=args.sep,
        verbose=args.verbose,
    )


if __name__ == "__main__":
    entry_point()
```

## File: src/crem/cli/fragmentation.py
```python
"""Fragment input compounds by cutting bonds matching specific SMARTS patterns.

This module provides a command-line interface (CLI) to read SMILES from an
input file, optionally accompanied by an ID, and fragment them using RDKit
(`rdMMPA`), with options for heavy-atom-only or hydrogen-only splitting modes.
Results are written to an output file, which may include duplicated lines
that can be handled externally.

Note:
    - A file named `__init__.py` must exist in the same `cli` folder to avoid
      implicit namespace package warnings (INP001).
    - We have replaced magic numbers 2 and 60 with constants (`HYDROGEN_SPLIT_ATOMS` and
      `MAX_HYDROGENS_ALLOWED`) to address Ruff's suggestions.
    - We merged repeated equality checks into membership checks (`mode in {0, 1}`, etc.).
    - We switched from percent-formatting to f-strings, added trailing commas,
      and replaced nested `with` statements with a single context manager.
    - `# noqa` comments are used where we must suppress certain warnings
      (e.g., too many arguments in a function) without changing the logic.

"""

__author__ = "pavel"

import argparse
import sys
from functools import partial
from multiprocessing import Pool, cpu_count
from pathlib import Path

from rdkit import Chem
from rdkit.Chem import rdMMPA

# Constants to replace magic values:
HYDROGEN_SPLIT_ATOMS = 2
MAX_HYDROGENS_ALLOWED = 60


def fragment_mol(
    smi: str,
    smi_id: str = "",
    mode: int = 0,
    sep_out: str = ",",
) -> set[str]:
    """Fragment a molecule based on a given mode, returning a set of output lines.

    Args:
        smi (str): The SMILES string for the molecule.
        smi_id (str): An optional ID for the molecule. Defaults to "".
        mode (int): Fragmentation mode.
            - 0: All atoms form a fragment.
            - 1: Heavy-atom only splitting.
            - 2: Hydrogen-atom only splitting.
            Defaults to 0.
        sep_out (str): The output separator for fields in the resulting lines.

    Returns:
        Set[str]: A set of lines with SMILES, ID, core, chains, and newline appended.

    """
    mol = Chem.MolFromSmiles(smi)
    outlines: set[str] = set()

    if mol is None:
        # Convert percent-format to f-string
        sys.stderr.write(f"Can't generate mol for: {smi}\n")
    else:
        # heavy atoms
        if mode in {0, 1}:  # PLR1714: merging (mode == 0) or (mode == 1)
            frags = rdMMPA.FragmentMol(
                mol,
                pattern="[!#1]!@!=!#[!#1]",
                maxCuts=4,
                resultsAsMols=False,
                maxCutBonds=30,
            )
            frags += rdMMPA.FragmentMol(
                mol,
                pattern="[!#1]!@!=!#[!#1]",
                maxCuts=3,
                resultsAsMols=False,
                maxCutBonds=30,
            )
            frags = set(frags)
            for core, chains in frags:
                # Add a trailing comma (COM812) after the last argument if multi-line
                output = sep_out.join((smi, smi_id, core, chains)) + "\n"
                outlines.add(output)

        # hydrogen splitting
        if mode in {1, 2}:  # merging (mode == 1) or (mode == 2)
            mol = Chem.AddHs(mol)
            n = mol.GetNumAtoms() - mol.GetNumHeavyAtoms()
            if n < MAX_HYDROGENS_ALLOWED:  # Replace magic value 60
                frags = rdMMPA.FragmentMol(
                    mol,
                    pattern="[#1]!@!=!#[!#1]",
                    maxCuts=1,
                    resultsAsMols=False,
                    maxCutBonds=100,  # trailing comma
                )
                for core, chains in frags:
                    output = sep_out.join((smi, smi_id, core, chains)) + "\n"
                    outlines.add(output)

    return outlines


def process_line(
    line: str,
    sep: str | None,
    mode: int,
    sep_out: str,
) -> set[str] | None:
    """Process a single line from the input file, returning a set of fragment lines or None.

    Args:
        line (str): A single line read from the input file.
        sep (Optional[str]): The input file separator (default is None, meaning Tab).
        mode (int): Fragmentation mode (0, 1, or 2).
        sep_out (str): The separator for the resulting output lines.

    Returns:
        Optional[Set[str]]: A set of lines containing fragment info, or None if line is empty.

    """
    tmp = line.strip().split(sep)
    if not tmp:
        return None
    if len(tmp) == 1:
        return fragment_mol(tmp[0], mode=mode, sep_out=sep_out)
    return fragment_mol(tmp[0], tmp[1], mode=mode, sep_out=sep_out)


def main(  # noqa: PLR0913
    input_fname: str,
    output_fname: str,
    mode: int,
    sep: str | None,
    ncpu: int,
    sep_out: str,
    verbose: bool,
) -> None:
    """Fragment an entire file of SMILES, writing results to an output file.

    Args:
        input_fname (str): Path to the input file (SMILES, optionally ID).
        output_fname (str): Path to the output file for storing fragments.
        mode (int): Fragmentation mode (0, 1, or 2).
        sep (Optional[str]): Separator in the input file. If None, defaults to Tab.
        ncpu (int): Number of CPU cores to use.
        sep_out (str): The output separator (default comma).
        verbose (bool): Whether to print progress to stderr.

    Returns:
        None

    """
    ncpu = min(cpu_count(), max(ncpu, 1))
    p = Pool(ncpu)

    # Merge nested with statements into one (SIM117) and use Path.open() (PTH123).
    with Path(output_fname).open("w") as out, Path(input_fname).open("r") as f:
        for i, res in enumerate(
            p.imap_unordered(
                partial(process_line, sep=sep, mode=mode, sep_out=sep_out),
                f,
                chunksize=100,
            ),
            1,
        ):
            if res:
                out.write("".join(res))

            if verbose and i % 1000 == 0:
                # Convert percent-format to f-string
                sys.stderr.write(f"\r{i} molecules fragmented")
                sys.stderr.flush()

    p.close()


def entry_point() -> None:
    """CLI entry point to parse arguments and execute `main` for fragmentation.

    This function sets up an argument parser for the fragmentation script,
    reads the user inputs, and calls `main()` with the parsed values.
    """
    parser = argparse.ArgumentParser(
        description="Fragment input compounds by cutting bonds matching bond SMARTS.",
    )
    parser.add_argument(
        "-i",
        "--input",
        metavar="input.smi",
        required=True,
        help="Input SMILES with optional comma-separated ID).",
    )
    parser.add_argument(
        "-o",
        "--out",
        metavar="output.txt",
        required=True,
        help="Fragmented molecules.",
    )
    parser.add_argument(
        "-s",
        "--sep",
        metavar="STRING",
        required=False,
        default=None,
        help="Separator in input file. Default: Tab.",
    )
    parser.add_argument(
        "-d",
        "--sep_out",
        metavar="STRING",
        required=False,
        default=",",
        help="Separator in the output file. Default: comma",
    )
    parser.add_argument(
        "-m",
        "--mode",
        metavar="INTEGER",
        required=False,
        default=0,
        choices=[0, 1, 2],
        type=int,
        help=(
            "Fragmentation mode: 0 - all atoms constitute a fragment, 1 - heavy atoms only, "
            "2 - hydrogen atoms only. Default: 0."
        ),
    )
    parser.add_argument(
        "-c",
        "--ncpu",
        metavar="NUMBER",
        required=False,
        default=1,
        help="Number of cpus used for computation. Default: 1.",
    )
    parser.add_argument(
        "-v",
        "--verbose",
        action="store_true",
        default=False,
        help="Print progress.",
    )

    args = vars(parser.parse_args())
    for o, v in args.items():
        if o == "input":
            input_fname = v
        elif o == "out":
            output_fname = v
        elif o == "verbose":
            verbose = v
        elif o == "ncpu":
            ncpu = int(v)
        elif o == "sep":
            sep = v
        elif o == "sep_out":
            sep_out = v
        elif o == "mode":
            mode = v

    main(
        input_fname=input_fname,
        output_fname=output_fname,
        mode=mode,
        sep=sep,
        ncpu=ncpu,
        sep_out=sep_out,
        verbose=verbose,
    )


if __name__ == "__main__":
    entry_point()
```

## File: src/crem/cli/guacamol_crem_test.py
```python
#!/usr/bin/env python3
# ==============================================================================
# author          : Pavel Polishchuk
# date            : 26-06-2019
# version         :
# python_version  : 3.8+
# copyright       : Pavel Polishchuk 2019
# license         :
# ==============================================================================

import argparse
import json
import logging
import os
from collections.abc import Sequence
from pathlib import Path
from time import time

import joblib
import numpy as np
import pandas as pd
from guacamol.assess_goal_directed_generation import assess_goal_directed_generation
from guacamol.goal_directed_generator import GoalDirectedGenerator
from guacamol.scoring_function import ScoringFunction
from joblib import delayed
from line_profiler import profile
from numpy.typing import NDArray
from rdkit import Chem
from rdkit.Chem.rdchem import Mol
from rich.logging import RichHandler

# -- RICH IMPORTS --
from rich.traceback import install as install_rich_traceback

# IMPORTANT:
# Make sure this import is from your actual local crem code, e.g.:
# from crem.crem import mutate_mol2
# or relative import if your structure is different.
from crem.core.operations import mutate_mol2


def setup_rich_logger(log_level: int = logging.INFO) -> logging.Logger:
    """Create and configure a custom logger that uses Rich for pretty, colorful logging.

    Args:
        log_level: The desired log level, e.g. logging.INFO, logging.DEBUG, etc.

    Returns:
        A configured logging.Logger instance using RichHandler.

    """
    # Rich can show nicer, colorized tracebacks
    install_rich_traceback(show_locals=False)

    # Create a new logger with a RichHandler
    # format="%(message)s" ensures RichHandler does its default styling
    logging.basicConfig(
        level=log_level,
        format="%(message)s",  # Let Rich handle the formatting style
        datefmt="[%X]",
        handlers=[RichHandler(rich_tracebacks=True)],
    )

    logger = logging.getLogger(__name__)
    logger.setLevel(log_level)

    # Optionally hush RDKit warnings to a certain level:
    # logging.getLogger("rdkit").setLevel(logging.WARNING)

    return logger


def make_mating_pool(
    population_mol: Sequence[Mol],
    population_scores: Sequence[float],
    offspring_size: int,
) -> NDArray[Mol]:
    """Given a population of RDKit Mol and their scores, sample a list of the same size
    with replacement using the population_scores as weights.

    Args:
        population_mol: Sequence of RDKit Mol
        population_scores: Sequence of un-normalised scores given by ScoringFunction
        offspring_size: number of molecules to return

    Returns:
        NDArray of RDKit Mol (probably not unique)

    """
    sum_scores = sum(population_scores)
    population_probs = [p / sum_scores for p in population_scores]
    mating_pool = np.random.choice(
        population_mol,
        p=population_probs,
        size=offspring_size,
        replace=True,
    )
    return mating_pool


def score_mol(mol: Mol, score_fn) -> float:
    """Score a single molecule using the provided scoring function."""
    return score_fn(Chem.MolToSmiles(mol))


class CREM_Generator(GoalDirectedGenerator):
    def __init__(
        self,
        smi_file: str | Path,
        selection_size: int,
        db_fname: str | Path,
        radius: int,
        replacements: int,
        max_size: int,
        min_size: int,
        max_inc: int,
        min_inc: int,
        generations: int,
        ncpu: int,
        random_start: bool,
        output_dir: str | Path,
    ):
        """Initialize the CREM_Generator with all needed parameters."""
        super().__init__()
        self.logger = logging.getLogger(__name__)

        self.pool = joblib.Parallel(n_jobs=ncpu)
        self.smiles = self.load_smiles_from_file(smi_file)
        self.N = selection_size
        self.db_fname = db_fname
        self.radius = radius
        self.min_size = min_size
        self.max_size = max_size
        self.min_inc = min_inc
        self.max_inc = max_inc
        self.replacements = replacements
        self.replacements_baseline = replacements
        self.generations = generations
        self.random_start = random_start
        self.patience1 = 3
        self.patience2 = 10
        self.patience3 = 33
        self.task = 0
        self.output_dir = Path(output_dir)

    def load_smiles_from_file(self, smi_file: str | Path) -> list[str]:
        """Load SMILES strings from a file."""
        self.logger.debug(f"Loading SMILES from file: {smi_file}")
        with open(smi_file) as f:
            lines = [line.strip() for line in f]
        self.logger.info(f"Loaded {len(lines)} SMILES from file.")
        return lines

    def top_k(self, smiles: Sequence[str], scoring_function: ScoringFunction, k: int) -> list[str]:
        """Score each SMILES, then sort them and return the top k."""
        self.logger.debug(f"Scoring {len(smiles)} SMILES to find top {k}.")
        joblist = (delayed(scoring_function.score)(s) for s in smiles)
        scores = self.pool(joblist)
        scored_smiles = sorted(zip(scores, smiles, strict=False), key=lambda x: x[0], reverse=True)
        top_smiles = [smile for score, smile in scored_smiles][:k]
        self.logger.debug(f"Top {len(top_smiles)} SMILES selected.")
        return top_smiles

    @profile
    def generate(self, smiles: Sequence[str]) -> list[str]:
        """Given a list of SMILES, generate new molecules using mutate_mol2 from the CREM library."""
        self.logger.debug(f"Generating new molecules from {len(smiles)} SMILES...")
        mols = [Chem.AddHs(Chem.MolFromSmiles(s)) for s in smiles]
        res = self.pool(
            delayed(mutate_mol2)(
                mol,
                db_name=self.db_fname,
                radius=self.radius,
                min_size=self.min_size,
                max_size=self.max_size,
                min_rel_size=0,
                max_rel_size=1,
                min_inc=self.min_inc,
                max_inc=self.max_inc,
                max_replacements=self.replacements,
                replace_cycles=False,
                protected_ids=None,
                min_freq=0,
                return_rxn=False,
                return_rxn_freq=False,
                ncores=1,
            )
            for mol in mols
        )
        # Flatten nested lists, remove duplicates
        new_smiles = list(set(m for sublist in res for m in sublist))
        self.logger.debug(f"Generated {len(new_smiles)} new unique SMILES.")
        return new_smiles

    def set_params(self, score: float) -> None:
        """Adjust generation parameters based on the current best score."""
        self.logger.debug(f"Adjusting parameters based on best score of {score:.3f}")
        self.replacements = self.replacements_baseline
        if score > 0.8:
            self.min_inc, self.max_inc = -4, 4
        elif score > 0.7:
            self.min_inc, self.max_inc = -5, 5
        elif score > 0.6:
            self.min_inc, self.max_inc = -6, 6
        elif score > 0.5:
            self.min_inc, self.max_inc = -7, 7
        elif score > 0.4:
            self.min_inc, self.max_inc = -8, 8
        elif score > 0.3:
            self.min_inc, self.max_inc = -9, 9
        else:
            self.min_inc, self.max_inc = -10, 10

    def get_scores(self, scoring_function: ScoringFunction, smiles: Sequence[str]) -> list[float]:
        """Convert SMILES to RDKit Mols and score them with the given scoring function."""
        self.logger.debug(f"Scoring {len(smiles)} SMILES.")
        mols = [Chem.MolFromSmiles(s) for s in smiles]
        return self.pool(delayed(score_mol)(m, scoring_function.score) for m in mols)

    def generate_optimized_molecules(
        self,
        scoring_function: ScoringFunction,
        number_molecules: int,
        starting_population: list[str] | None = None,
    ) -> list[str]:
        """Main evolutionary loop:
        1. Initialize or take a given starting population.
        2. Generate new molecules, score them, keep the top scorers.
        3. Update parameters, repeat.
        """
        self.task += 1
        self.logger.info(f"Starting generation process for task #{self.task}")
        self.logger.info(f"Requested number of molecules: {number_molecules}")

        if number_molecules > self.N:
            self.N = number_molecules
            self.logger.warning(
                "Benchmark requested more molecules than expected. " f"New population size is {number_molecules}",
            )

        # Select initial population
        if starting_population is None:
            self.logger.info("Selecting initial population...")
            if self.random_start:
                initial_smiles = np.random.choice(self.smiles, self.N)
                self.logger.debug(f"Randomly selected {self.N} SMILES as initial population.")
            else:
                initial_smiles = self.top_k(self.smiles, scoring_function, self.N)
                self.logger.debug(f"Selected top {self.N} SMILES from the input database.")
            population = pd.DataFrame({"smi": initial_smiles})
        else:
            population = pd.DataFrame({"smi": starting_population})
            self.logger.info(f"Using provided starting population of size {len(population)}.")

        # Calculate initial scores
        population["score"] = self.get_scores(scoring_function, population["smi"])

        # Evolution loop setup
        t0 = time_start = time()
        patience1 = patience2 = patience3 = 0
        best = population.copy()
        ref_score = np.mean(best["score"].iloc[:number_molecules])
        self.set_params(best["score"].max())
        used_smiles = set(population["smi"])

        self.logger.info(f"Initial best average score: {ref_score:.3f}")

        for generation in range(self.generations):
            if ref_score == 1.0:
                self.logger.info(f"Perfect score reached at generation {generation}. Stopping early.")
                break

            self.logger.debug(f"Generating new population (gen {generation})...")
            new_smiles = self.generate(population["smi"])
            population = pd.DataFrame({"smi": new_smiles})
            population["score"] = self.get_scores(scoring_function, population["smi"])

            # Combine old best + new population, remove duplicates, keep top N
            combined = pd.concat([best, population], ignore_index=True)
            combined = combined.drop_duplicates(subset="smi")
            combined = combined.sort_values(by="score", ascending=False)
            best = combined.head(self.N)

            # Evaluate the new best average score
            cur_score = np.mean(best["score"].iloc[:number_molecules])
            self.logger.debug(f"Current score for generation {generation}: {cur_score:.3f}")

            if cur_score > ref_score:
                # We found improvement
                ref_score = cur_score
                population = population.head(self.N)
                self.set_params(population["score"].max())
                used_smiles.update(population["smi"])
                patience1 = patience2 = patience3 = 0
                self.logger.info(
                    f"Improvement found at generation {generation}. New best avg: {ref_score:.3f}",
                )
            else:
                # No improvement, increment patience counters
                patience1 += 1
                patience2 += 1
                patience3 += 1

                self.logger.debug(
                    f"No improvement at generation {generation}. "
                    f"Patience counters: p1={patience1}, p2={patience2}, p3={patience3}",
                )

                if patience3 >= self.patience3:
                    self.logger.info(f"Maximum patience (p3) reached at generation {generation}.")
                    if starting_population is None and self.random_start:
                        self.logger.warning("Resetting population from random SMILES due to p3 threshold.")
                        patience1 = patience2 = patience3 = 0
                        initial_smiles = np.random.choice(self.smiles, self.N)
                        population = pd.DataFrame({"smi": initial_smiles})
                        population["score"] = self.get_scores(scoring_function, population["smi"])
                        population = population.sort_values("score", ascending=False)
                        self.set_params(population["score"].max())
                        used_smiles = set(population["smi"])
                    else:
                        # Stop the evolutionary loop
                        self.logger.info(f"Stopping evolutionary loop at generation {generation}.")
                        break
                else:
                    # Keep only top N
                    population = population.head(self.N)
                    used_smiles.update(population["smi"])

                    if patience2 >= self.patience2:
                        # Medium-level patience threshold
                        self.logger.info("p2 threshold reached; relaxing parameters further.")
                        patience1 = patience2 = 0
                        self.min_inc -= 10
                        self.max_inc += 10
                        self.replacements += 500
                    elif patience1 >= self.patience1:
                        # Small patience threshold
                        self.logger.info("p1 threshold reached; adjusting parameters slightly.")
                        patience1 = 0
                        self.min_inc -= 1
                        self.max_inc += 1
                        self.replacements += 100

            # Print generation statistics
            gen_time = time() - t0
            t0 = time()
            self.logger.info(
                f"Gen {generation:3d} | best avg: {np.mean(best['score'].iloc[:number_molecules]):.3f} "
                f"| max: {population['score'].max():.3f} | avg: {population['score'].mean():.3f} "
                f"| min: {population['score'].min():.3f} | std: {population['score'].std():.3f} "
                f"| sum: {population['score'].sum():.3f} "
                f"| min_inc: {self.min_inc} | max_inc: {self.max_inc} | repl: {self.replacements} "
                f"| p1: {patience1} | p2: {patience2} | p3: {patience3} | {gen_time:.2f} sec",
            )

            # 5-hour time limit
            if t0 - time_start > 18000:
                self.logger.warning(
                    f"Time limit (5 hours) reached. Stopping early at generation {generation}.",
                )
                break

        # Save results to a .smi file
        output_path = Path(self.output_dir) / f"{self.task}.smi"
        best.round({"score": 3}).to_csv(
            output_path,
            sep="\t",
            header=False,
            index=False,
        )
        self.logger.info(f"Saved best molecules for task #{self.task} to {output_path}")

        # Return the top (number_molecules) SMILES
        return best["smi"].iloc[:number_molecules].tolist()


def entry_point():
    parser = argparse.ArgumentParser()
    parser.add_argument("--smiles_file", type=str, required=True)
    parser.add_argument("--db_fname", type=str, required=True)
    parser.add_argument("--selection_size", type=int, default=10)
    parser.add_argument("--radius", type=int, default=3)
    parser.add_argument("--replacements", type=int, default=1000)
    parser.add_argument("--min_size", type=int, default=0)
    parser.add_argument("--max_size", type=int, default=10)
    parser.add_argument("--min_inc", type=int, default=-7)
    parser.add_argument("--max_inc", type=int, default=7)
    parser.add_argument("--generations", type=int, default=1000)
    parser.add_argument("--ncpu", type=int, default=1)
    parser.add_argument("--seed", type=int, default=42)
    parser.add_argument("--output_dir", type=str, default=None)
    parser.add_argument("--suite", default="v2")
    parser.add_argument("--log_level", type=str, default="INFO", help="Set log level (DEBUG, INFO, WARNING, ERROR).")

    args = parser.parse_args()

    # Convert string log_level to a logging constant, e.g. "INFO" -> logging.INFO
    numeric_level = getattr(logging, args.log_level.upper(), logging.INFO)
    logger = setup_rich_logger(log_level=numeric_level)

    np.random.seed(args.seed)
    logger.info(f"Random seed set to {args.seed}")

    # Determine output directory
    output_dir = Path(args.output_dir or os.path.dirname(os.path.realpath(__file__)))
    output_dir.mkdir(parents=True, exist_ok=True)

    # Save the command-line args for reference
    param_file = output_dir / "goal_directed_params.json"
    with open(param_file, "w") as jf:
        json.dump(vars(args), jf, sort_keys=True, indent=4)
    logger.info(f"Saved parameters to {param_file}")

    # Create optimizer
    optimiser = CREM_Generator(
        smi_file=args.smiles_file,
        selection_size=args.selection_size,
        db_fname=args.db_fname,
        radius=args.radius,
        min_size=args.min_size,
        max_size=args.max_size,
        min_inc=args.min_inc,
        max_inc=args.max_inc,
        replacements=args.replacements,
        generations=args.generations,
        ncpu=args.ncpu,
        random_start=True,
        output_dir=output_dir,
    )

    # JSON output for the benchmark
    json_file_path = output_dir / "goal_directed_results.json"
    logger.info(f"Running GuacaMol assessment with suite={args.suite}")

    # Evaluate the generator using GuacaMol's goal-directed benchmark suite
    assess_goal_directed_generation(
        optimiser,
        json_output_file=json_file_path,
        benchmark_version=args.suite,
    )
    logger.info(f"Finished all benchmarks. Results saved to {json_file_path}")


if __name__ == "__main__":
    entry_point()
```

## File: src/crem/cli/import_env_to_db.py
```python
"""Create a SQLite DB from a text file with environment and core fragment data.

This module reads a file containing environment SMILES, core SMILES, core atom
counts, etc. It then creates (or replaces) a table named `radiusX` (where X is
the specified radius) in the output SQLite database, adding columns for
environment, core, distance, frequency, etc. as needed. If the user passes
`--counts`, the input file is assumed to have a frequency count in front of each
line. The script can use multiprocessing to speed up calculations of an RDKit
reaction SMARTS for each row.

**Important**:
    - Create `__init__.py` in the same directory (`cli`) to fix any implicit
      namespace package warnings.
    - The logic in this script remains unchanged; only docstrings, type hints,
      and minimal linting-related updates have been applied to satisfy Ruff
      checks.

Example usage:
    python import_env_to_db.py -i env_frags.txt -o output.db -r 3 --counts -n 4 -v

"""

import argparse
import re
import sqlite3
import sys
from multiprocessing import Pool, cpu_count
from pathlib import Path

from rdkit import Chem

from crem.utils.mol_context import combine_core_env_to_rxn_smarts

__author__ = "pavel"

# Use a named constant for the '2' magic number (PLR2004).
TWO_DUMMIES = 2


def __calc(env: str, core: str) -> tuple[str, float]:
    """Compute the reaction SMARTS (using `combine_core_env_to_rxn_smarts`) and distance.

    If the `core` has exactly two dummy atoms, we measure the distance between those dummy
    atoms in the RDKit distance matrix. Otherwise, the distance is 0.

    Args:
        env (str): Environment SMILES.
        core (str): Core SMILES.

    Returns:
        Tuple[str, float]: A tuple of (reaction_smarts, distance).

    """
    sma = combine_core_env_to_rxn_smarts(core, env, keep_h=False)  # FBT003 => specify param name
    if core.count("*") == TWO_DUMMIES:  # replaced magic '2'
        mol = Chem.MolFromSmiles(core, sanitize=False)
        mat = Chem.GetDistanceMatrix(mol)
        ids = []
        # PERF401: use list comp
        ids = [a.GetIdx() for a in mol.GetAtoms() if not a.GetAtomicNum()]

        dist2 = mat[ids[0], ids[1]]
    else:
        dist2 = 0
    return sma, dist2


def __calc_mp(items: tuple[str, str]) -> tuple[str, float]:
    """Multiprocessing-friendly wrapper for `__calc`.

    Args:
        items (Tuple[str, str]): A tuple of (env, core).

    Returns:
        Tuple[str, float]: The results from `__calc(env, core)`.

    """
    return __calc(*items)


def __get_additional_data(
    data: list[tuple[str, str]],
    pool,  # noqa: ANN001
) -> list[tuple[str, float]]:
    """Compute additional data (reaction SMARTS, distance) for each (env, core) pair.

    If a multiprocessing Pool is provided, it uses it to map `__calc_mp`;
    otherwise, it calls `__calc` sequentially.

    Args:
        data (List[Tuple[str, str]]): A list of (env, core) pairs.
        pool (Optional[Pool]): The multiprocessing pool, or None.

    Returns:
        List[Tuple[str, float]]: A list of (reaction_smarts, distance) results.

    """
    # SIM108 => ternary operator instead of if-else
    return (
        [items for items in pool.imap(__calc_mp, data, chunksize=100)]  # C416 can be simplified
        if pool
        else [__calc(*items) for items in data]
    )


def main(  # noqa: PLR0913, PLR0912
    input_fname: str,
    output_fname: str,
    radius: int,
    counts: bool,
    ncpu: int,
    verbose: bool,
) -> None:
    """Create or replace a table `radiusN` in a SQLite DB with environment/core info.

    Reads data from a CSV/space-delimited file, extracting environment SMILES, core SMILES,
    number of atoms, and optionally frequency (if `--counts` is used). Then calculates
    additional data (reaction SMARTS, distance) and writes results to a new or replaced
    table named `radiusX` (where X is the specified radius). Also creates an index on `env`.

    Args:
        input_fname (str): The path to the input text file.
        output_fname (str): The path to the output SQLite DB.
        radius (int): The radius of environment. A table named `radius{radius}` is created.
        counts (bool): If True, the input includes a frequency column at the start.
        ncpu (int): The number of CPU cores to use for parallel processing.
        verbose (bool): If True, prints progress to stderr.

    Returns:
        None

    """
    pool = Pool(min(ncpu, cpu_count())) if ncpu > 1 else None

    table_name = f"radius{radius}"

    with sqlite3.connect(output_fname) as conn:
        cur = conn.cursor()

        # Use format specifiers (UP031). S608 suppressed with `# nosec`
        drop_sql = f"DROP TABLE IF EXISTS {table_name}"  # nosec
        cur.execute(drop_sql)

        if counts:
            # trailing commas for multi-line
            create_sql = (
                f"CREATE TABLE {table_name}("
                "env TEXT NOT NULL, "
                "core_smi TEXT NOT NULL, "
                "core_num_atoms INTEGER NOT NULL, "
                "core_sma TEXT NOT NULL, "
                "dist2 INTEGER NOT NULL, "
                "freq INTEGER NOT NULL"
                ")"
            )
        else:
            create_sql = (
                f"CREATE TABLE {table_name}("
                "env TEXT NOT NULL, "
                "core_smi TEXT NOT NULL, "
                "core_num_atoms INTEGER NOT NULL, "
                "core_sma TEXT NOT NULL,"
                "dist2 INTEGER NOT NULL"
                ")"
            )
        cur.execute(create_sql)  # nosec
        conn.commit()

        buf = []
        # PTH123 => Path.open
        with Path(input_fname).open("r") as f:
            for i, line in enumerate(f):
                if counts:
                    tmp = re.split(r"[,\s]+", line.strip())  # broad match for comma or space
                    # move the first item to the end (the frequency)
                    tmp.append(tmp.pop(0))
                    buf.append(tuple(tmp))
                else:
                    buf.append(tuple(line.strip().split(",")))
                if (i + 1) % 100000 == 0:
                    adata = __get_additional_data([items[:2] for items in buf], pool)
                    if counts:
                        # zip with strict=False => Python 3.10+
                        # prefer f-string
                        # S608 => # nosec
                        buf = [a[:-1] + b + (a[-1],) for a, b in zip(buf, adata, strict=False)]
                        insert_sql = f"INSERT INTO {table_name} VALUES (?, ?, ?, ?, ?, ?)"  # nosec
                        cur.executemany(insert_sql, buf)
                    else:
                        buf = [a + b for a, b in zip(buf, adata, strict=False)]
                        insert_sql = f"INSERT INTO {table_name} VALUES (?, ?, ?, ?, ?)"  # nosec
                        cur.executemany(insert_sql, buf)

                    conn.commit()
                    buf = []
                    if verbose:
                        sys.stderr.write(f"\r{i + 1} lines proceed")
                        sys.stderr.flush()

        if buf:
            adata = __get_additional_data([items[:2] for items in buf], pool)
            if counts:
                buf = [a[:-1] + b + (a[-1],) for a, b in zip(buf, adata, strict=False)]
                insert_sql = f"INSERT INTO {table_name} VALUES (?, ?, ?, ?, ?, ?)"  # nosec
                cur.executemany(insert_sql, buf)
            else:
                buf = [a + b for a, b in zip(buf, adata, strict=False)]
                insert_sql = f"INSERT INTO {table_name} VALUES (?, ?, ?, ?, ?)"  # nosec
                cur.executemany(insert_sql, buf)
            conn.commit()

        idx_name = f"{table_name}_env_idx"
        drop_idx_sql = f"DROP INDEX IF EXISTS {idx_name}"  # nosec
        create_idx_sql = f"CREATE INDEX {idx_name} ON {table_name} (env)"  # nosec
        cur.execute(drop_idx_sql)  # nosec
        cur.execute(create_idx_sql)  # nosec
        conn.commit()

    if pool is not None:
        pool.close()


def entry_point() -> None:
    """Parse command-line arguments and create a SQLite DB from environment/core data.

    This entry point reads environment and core fragment data from a file,
    calculates a reaction SMARTS and distance, then populates a SQLite
    database table named `radiusX`.

    Example:
        import_env_to_db -i env_frags.txt -o fragments.db -r 3 -c -n 4 -v

    Returns:
        None

    """
    parser = argparse.ArgumentParser(
        description=(
            "Create SQLite DB from a text file containing env_smi, core_smi, core_atom_num "
            "and core_sma. If --counts is set, the file includes a frequency column in front."
        ),
    )
    parser.add_argument(
        "-i",
        "--input",
        metavar="env_frags.txt",
        required=True,
        help=("A comma-separated text file with env_smi, core_smi, core_atom_num, and core_sma."),
    )
    parser.add_argument(
        "-o",
        "--out",
        metavar="output.db",
        required=True,
        help="Path to the output SQLite DB file.",
    )
    parser.add_argument(
        "-r",
        "--radius",
        metavar="RADIUS",
        required=True,
        help=(
            "Radius of environment. If a table for this radius value already "
            "exists in the output DB, it will be dropped."
        ),
    )
    parser.add_argument(
        "-c",
        "--counts",
        action="store_true",
        default=False,
        help=(
            "If set, the input file contains a frequency as the first column "
            "(e.g., output of `sort|uniq -c`). This adds a column freq to the DB."
        ),
    )
    parser.add_argument(
        "-n",
        "--ncpu",
        default=1,
        help="Number of CPUs to use. Default: 1.",
    )
    parser.add_argument(
        "-v",
        "--verbose",
        action="store_true",
        default=False,
        help="Print progress to stderr.",
    )

    args = vars(parser.parse_args())
    input_fname: str = args["input"]
    output_fname: str = args["out"]
    radius: int = int(args["radius"])
    counts: bool = args["counts"]
    ncpu: int = int(args["ncpu"])
    verbose: bool = args["verbose"]

    main(
        input_fname=input_fname,
        output_fname=output_fname,
        radius=radius,
        counts=counts,
        ncpu=ncpu,
        verbose=verbose,
    )


if __name__ == "__main__":
    entry_point()
```

## File: src/crem/cli/main_optuna_crem.py
```python
import json
import shutil
import tempfile
from pathlib import Path

import numpy as np
import optuna
from guacamol.assess_goal_directed_generation import assess_goal_directed_generation
from guacamol.utils.helpers import setup_default_logger

from crem.guacamol_crem_test import CREM_Generator


def crem_optuna_objective(trial: optuna.trial.Trial) -> float:
    """This objective function runs a short iterative search (like from the CReM paper)
    with user-tunable parameters. 
    We'll measure how well the generated molecules achieve some internal "score."
    
    Return a single scalar to be *maximized*. 
    """
    # 1. Let trial pick hyperparameters
    #    (We rely heavily on CReM's approach: radius, replacements, inc, fragment occurrence, etc.)
    radius = trial.suggest_int("radius", 1, 5)
    replacements = trial.suggest_int("replacements", 100, 2000, step=100)
    # optional frequency cutoff
    min_freq = trial.suggest_int("min_freq", 0, 1000, step=50)
    # maybe we vary the generation approach
    generations = trial.suggest_int("generations", 50, 200, step=50)

    # 2. We'll create a temporary output dir for each trial
    temp_dir = Path(tempfile.mkdtemp(prefix="crem_optuna_trial_"))

    # 3. Create a CREM_Generator with these parameters
    #    (This is the code from your guacamol_crem_test.py, with fields overridden)
    generator = CREM_Generator(
        smi_file = "/Users/thomasgraham/prj/crem/example/CHEMBL231.smi",
        selection_size=10,
        db_fname="/Users/thomasgraham/prj/crem/db_output/fragments.db",   # The pre-built fragment DB from step #1
        radius=radius,
        replacements=replacements,
        min_size=0,
        max_size=10,
        min_inc=-7,
        max_inc=7,
        generations=generations,
        ncpu=10,
        random_start=True,
        output_dir=temp_dir,
    )
    # Optionally set the 'min_freq' in the generator, if the code supports it:
    generator.min_freq = min_freq

    # 4. We do a *short* assess_goal_directed_generation
    #    - E.g., we rely on GuacaMol to measure "overall_score" for a single benchmark,
    #      or you define a custom measure.
    setup_default_logger()
    out_json = temp_dir / "trial_results.json"

    # For demonstration, we run a single (or small subset) GuacaMol tasks for speed:
    try:
        assess_goal_directed_generation(
            generator,
            json_output_file=out_json,
            benchmark_version="v2",  # or "v3"
        )
    except Exception as e:
        print(f"[WARNING] Trial failed: {e}")
        # Return something to indicate a low score
        shutil.rmtree(temp_dir, ignore_errors=True)
        return 0.0

    # 5. Parse the "trial_results.json" for a final 'score'
    try:
        with open(out_json) as f:
            data = json.load(f)
        # The GuacaMol JSON typically has a structure with a 'score' field,
        # or an array of tasks. We'll do a simple approach:
        #
        # The data might look like:
        #   {"benchmarks": [{"name": "...", "score": 0.82, ...}, {"name": "..."}],
        #    "metadata": {...}
        #   }
        # So we can sum or average the "score" fields:
        bench_scores = [b["score"] for b in data["benchmarks"]]
        score = float(np.mean(bench_scores))  # or sum, etc.
    except:
        score = 0.0

    # 6. Clean up
    shutil.rmtree(temp_dir, ignore_errors=True)

    return score  # to be *maximized* by Optuna

def run_optuna_for_crem():
    study = optuna.create_study(
        study_name="TuneCREM",
        direction="maximize",  # we want the best guacamol-based score
        # Optionally: storage="sqlite:///crem_optuna.db", load_if_exists=True
    )
    study.optimize(crem_optuna_objective, n_trials=20, n_jobs=1)

    print("Best Trial:")
    print(f"  Number: {study.best_trial.number}")
    print(f"  Value (score): {study.best_trial.value}")
    print("  Params:")
    for k, v in study.best_trial.params.items():
        print(f"    {k} = {v}")

def final_crem_run_with_best(study):
    best_params = study.best_trial.params
    # Suppose we only have radius, replacements, min_freq, generations
    # We'll do a bigger run:

    final_generator = CREM_Generator(
        smi_file         = "example_input_smiles.smi",
        db_fname         = "path/to/your_crem_fragdb.pkl",
        radius           = best_params["radius"],
        replacements     = best_params["replacements"],
        min_size         = 0,
        max_size         = 10,
        min_inc          = -7,
        max_inc          = 7,
        generations      = best_params["generations"],
        ncpu             = 2,
        random_start     = True,
        output_dir       = Path("final_crem_output"),
    )
    final_generator.min_freq = best_params["min_freq"]

    out_json = Path("final_results.json")
    setup_default_logger()
    assess_goal_directed_generation(
        final_generator,
        json_output_file=out_json,
        benchmark_version="v2",
    )
    print("[INFO] Final run results in final_results.json")

def main():
    # Possibly generate or load your fragment DB first if needed:
    #   smiles_for_db = load_my_chembl_subset()  # or whichever method
    #   generate_crem_db(smiles_for_db, "path/to/your_crem_fragdb.pkl", radius=3)

    # 1. Run Optuna
    run_optuna_for_crem()

    # 2. Suppose we want to do a final run
    #    We can retrieve the study from memory or from the storage
    #    Then pass it to final_crem_run_with_best(study)
    #    e.g. final_crem_run_with_best(study)
    #
    # If run_optuna_for_crem returns a study object:
    #    study = run_optuna_for_crem()
    #    final_crem_run_with_best(study)


if __name__ == "__main__":
    main()
```

## File: src/crem/core/fragmentation.py
```python
import re
from collections import defaultdict
from itertools import product

from rdkit import Chem
from rdkit.Chem import rdMMPA

from crem.utils.mol_context import get_canon_context_core, patt_remove_map

cycle_pattern = re.compile(r"[a-zA-Z\]][1-9]+")
Chem.SetDefaultPickleProperties(Chem.PropertyPickleOptions.AllProps)
patt_remove_brackets = re.compile(r"\(\)")


def __extend_output_by_equivalent_atoms(mol, output):
    atom_ranks = list(Chem.CanonicalRankAtoms(mol, breakTies=False, includeChirality=False, includeIsotopes=False))
    tmp = defaultdict(list)
    for i, rank in enumerate(atom_ranks):
        tmp[rank].append(i)
    atom_eq = dict()
    for ids in tmp.values():
        if len(ids) > 1:
            for i in ids:
                atom_eq[i] = [j for j in ids if j != i]

    extended_output = []
    for item in output:
        if all(i in atom_eq for i in item[2]):
            smi = patt_remove_map.sub("", item[1])
            smi = patt_remove_brackets.sub("", smi)
            ids_list = [set(i) for i in mol.GetSubstructMatches(Chem.MolFromSmarts(smi))]
            for ids_matched in ids_list:
                for ids_eq in product(*(atom_eq[i] for i in item[2])):
                    if ids_matched == set(ids_eq):
                        extended_output.append((item[0], item[1], tuple(sorted(ids_eq))))
    return extended_output


def __fragment_mol(
    mol,
    radius=3,
    return_ids=True,
    keep_stereo=False,
    protected_ids=None,
    symmetry_fixes=False,
):
    def get_atom_prop(molecule, prop="Index"):
        res = []
        for a in molecule.GetAtoms():
            if a.GetAtomicNum():
                res.append(a.GetIntProp(prop))
        return tuple(sorted(res))

    if protected_ids:
        return_ids = True

    output = set()

    if return_ids:
        for atom in mol.GetAtoms():
            atom.SetIntProp("Index", atom.GetIdx())

    frags = rdMMPA.FragmentMol(mol, pattern="[!#1]!@!=!#[!#1]", maxCuts=4, resultsAsMols=True, maxCutBonds=30)
    frags += rdMMPA.FragmentMol(mol, pattern="[!#1]!@!=!#[!#1]", maxCuts=3, resultsAsMols=True, maxCutBonds=30)
    frags += rdMMPA.FragmentMol(mol, pattern="[#1]!@!=!#[!#1]", maxCuts=1, resultsAsMols=True, maxCutBonds=100)

    for i, (core, chains) in enumerate(frags):
        if core is None:
            components = list(Chem.GetMolFrags(chains, asMols=True))
            ids_0 = get_atom_prop(components[0]) if return_ids else tuple()
            ids_1 = get_atom_prop(components[1]) if return_ids else tuple()
            if Chem.MolToSmiles(components[0]) != "[H][*:1]":
                env, frag = get_canon_context_core(components[0], components[1], radius, keep_stereo)
                output.add((env, frag, ids_1))
            if Chem.MolToSmiles(components[1]) != "[H][*:1]":
                env, frag = get_canon_context_core(components[1], components[0], radius, keep_stereo)
                output.add((env, frag, ids_0))
        else:
            env, frag = get_canon_context_core(chains, core, radius, keep_stereo)
            output.add((env, frag, get_atom_prop(core) if return_ids else tuple()))

    if symmetry_fixes:
        extended_output = __extend_output_by_equivalent_atoms(mol, output)
        if extended_output:
            output.update(extended_output)

    if protected_ids:
        protected_ids = set(protected_ids)
        output = [item for item in output if protected_ids.isdisjoint(item[2])]

    return list(output)


def __fragment_mol_link(
    mol1,
    mol2,
    radius=3,
    keep_stereo=False,
    protected_ids_1=None,
    protected_ids_2=None,
    return_ids=True,
):
    def filter_frags(frags, protected_ids):
        output = []
        protected_ids = set(protected_ids)
        for _, chains in frags:
            for atom in chains.GetAtoms():
                if atom.GetAtomicNum() == 0:
                    for d in atom.GetNeighbors():
                        if d.GetAtomicNum() != 1 and d.GetIdx() not in protected_ids:
                            output.append((None, chains))
        return output

    def prep_frags(frags, keep_stereo=False):
        ls = []
        for _, chains in frags:
            ids = []
            for atom in chains.GetAtoms():
                if atom.GetAtomicNum() == 0:
                    for d in atom.GetNeighbors():
                        if d.GetAtomicNum() == 1:
                            ids = [d.GetIntProp("Index")]
                if ids:
                    break
            a, b = Chem.MolToSmiles(chains, isomericSmiles=keep_stereo).split(".")
            if a == "[H][*:1]":
                ls.append([b, ids])
            else:
                ls.append([a, ids])
        return ls

    if protected_ids_1 or protected_ids_2:
        return_ids = True

    if return_ids:
        for atom in mol1.GetAtoms():
            atom.SetIntProp("Index", atom.GetIdx())
        for atom in mol2.GetAtoms():
            atom.SetIntProp("Index", atom.GetIdx())

    frags_1 = rdMMPA.FragmentMol(mol1, pattern="[#1]!@!=!#[!#1]", maxCuts=1, resultsAsMols=True, maxCutBonds=100)
    frags_2 = rdMMPA.FragmentMol(mol2, pattern="[#1]!@!=!#[!#1]", maxCuts=1, resultsAsMols=True, maxCutBonds=100)

    if protected_ids_1:
        frags_1 = filter_frags(frags_1, protected_ids_1)

    if protected_ids_2:
        frags_2 = filter_frags(frags_2, protected_ids_2)

    frags_1 = prep_frags(frags_1, keep_stereo)
    frags_2 = prep_frags(frags_2, keep_stereo)

    for i in range(len(frags_1)):
        frags_1[i][0] = frags_1[i][0].replace("*:1", "*:2")

    q = []
    for (fr1, ids1), (fr2, ids2) in product(frags_1, frags_2):
        q.append(["%s.%s" % (fr1, fr2), ids1, ids2])

    fake_core = "[*:1]C[*:2]"
    output = []

    for chains, ids_1, ids_2 in q:
        env, frag = get_canon_context_core(chains, fake_core, radius=radius, keep_stereo=keep_stereo)
        output.append((env, "[H][*:1].[H][*:2]", ids_1, ids_2))

    return output
```

## File: src/crem/core/functions.py
```python
#!/usr/bin/env python3
# ==============================================================================
# author          : Pavel Polishchuk
# date            : 31-08-2018
# version         :
# python_version  :
# copyright       : Pavel Polishchuk 2018
# license         :
# ==============================================================================

import re
import sys

from rdkit import Chem


def mol_to_smarts(mol, keep_h=True):
    # keep_h - will increase the count of H atoms for atoms with attached hydrogens to create a valid smarts
    # e.g. [H]-[CH2]-[*] -> [H]-[CH3]-[*]

    mol = Chem.Mol(mol)
    mol.UpdatePropertyCache()

    # change the isotope to 42
    for atom in mol.GetAtoms():
        if keep_h:
            s = sum(na.GetAtomicNum() == 1 for na in atom.GetNeighbors())
            if s:
                atom.SetNumExplicitHs(atom.GetTotalNumHs() + s)
        atom.SetIsotope(42)

    # print out the smiles - all the atom attributes will be fully specified
    smarts = Chem.MolToSmiles(mol, isomericSmiles=True, allBondsExplicit=True)
    # remove the 42 isotope labels
    smarts = re.sub(r"\[42", "[", smarts)

    return smarts


def smiles_to_smarts(smi, keep_h=True):
    mol = Chem.MolFromSmiles(smi, sanitize=False)
    if mol is None:
        sys.stderr.write("Can't generate mol for: %s\n" % smi)
        return None
    return mol_to_smarts(mol, keep_h)
```

## File: src/crem/core/operations.py
```python
"""operations.py.

Implements core operations for mutating, growing, and linking molecules using a fragment-based approach:
- mutate_mol
- grow_mol
- link_mols
- mutate_mol2, grow_mol2, link_mols2 (list-returning versions)
- get_replacements for advanced usage

We have addressed Ruff lint warnings by:
    - Adding docstrings, type hints
    - Suppressing or acknowledging complex / argument-count warnings (C901, PLR0912, PLR0913, PLR0915)
    - Removing unused imports
    - Converting or suppressing places where simpler comprehensions are suggested
    - Not changing underlying logic
"""

from multiprocessing import Pool, cpu_count

from rdkit import Chem

# We import from our replacement module
from crem.core.replacement import (
    __frag_replace,
    __frag_replace_mp,
    __gen_replacements,
    __get_data,
)

# We also import from fragmentation if needed


def mutate_mol(  # noqa: C901, PLR0913, PLR0912
    mol: Chem.Mol,
    db_name: str,
    radius: int = 3,
    min_size: int = 0,
    max_size: int = 10,
    min_rel_size: float = 0,
    max_rel_size: float = 1,
    min_inc: int = -2,
    max_inc: int = 2,
    max_replacements: int | None = None,
    replace_cycles: bool = False,  # noqa: FBT001, FBT002
    replace_ids: list[int] | None = None,
    protected_ids: list[int] | None = None,
    symmetry_fixes: bool = False,  # noqa: FBT001, FBT002
    min_freq: int = 0,
    return_rxn: bool = False,  # noqa: FBT001, FBT002
    return_rxn_freq: bool = False,  # noqa: FBT001, FBT002
    return_mol: bool = False,  # noqa: FBT001, FBT002
    ncores: int = 1,
    filter_func=None,  # noqa: ANN001
    sample_func=None,  # noqa: ANN001
    **kwargs,  # noqa: ANN003
) -> Chem.Mol | str | None:  # type: ignore  # noqa: PGH003
    """Mutate a molecule by substituting fragments from a database.

    Args:
        mol (Chem.Mol): The input molecule to mutate.
        db_name (str): The fragment DB name.
        radius (int): The context radius.
        min_size (int): Minimum heavy atoms in fragment replaced.
        max_size (int): Maximum heavy atoms in fragment replaced.
        min_rel_size (float): Minimum relative size ratio for fragment replaced.
        max_rel_size (float): Maximum relative size ratio for fragment replaced.
        min_inc (int): Min difference in size between replaced & new.
        max_inc (int): Max difference in size.
        max_replacements (Optional[int]): The cap on how many replacements to yield.
        replace_cycles (bool): If True, can replace ring fragments ignoring size constraints.
        replace_ids (Optional[List[int]]): Atom indices to replace.
        protected_ids (Optional[List[int]]): Atom indices to protect from replacement.
        symmetry_fixes (bool): Whether to attempt symmetrical expansions.
        min_freq (int): Min occurrence threshold in the DB.
        return_rxn (bool): If True, include the reaction SMARTS in output.
        return_rxn_freq (bool): If True, include the freq in output.
        return_mol (bool): If True, yield the RDKit product Mol instead of only SMILES.
        ncores (int): Number of CPU cores for parallel.
        filter_func: Optional user-supplied filter for row IDs.
        sample_func: Optional user-supplied sampling for row IDs.
        **kwargs: Additional parameters for advanced usage.

    Yields:
        - If return_mol=False, return_rxn=False: yields just the SMILES string
        - If one or more booleans are True, yields a tuple of details accordingly

    Returns:
        A generator that yields mutated structures (str or tuple).

    """
    products = {Chem.MolToSmiles(mol)}
    prot_set = set(protected_ids) if protected_ids else set()

    if replace_ids:
        ids = set()
        for i in replace_ids:
            ids.update(a.GetIdx() for a in mol.GetAtomWithIdx(i).GetNeighbors() if a.GetAtomicNum() == 1)
        all_ids = {a.GetIdx() for a in mol.GetAtoms()}
        # SIM102 => we won't flatten or we risk logic changes
        if ids:
            ids = all_ids.difference(ids).difference(replace_ids)
        prot_set.update(ids)

    protected_ids_sorted = sorted(prot_set)

    if ncores == 1:
        # Single core mode
        for frag_sma, core_sma, freq, ids in __gen_replacements(
            mol1=mol,
            mol2=None,
            db_name=db_name,
            radius=radius,
            min_size=min_size,
            max_size=max_size,
            min_rel_size=min_rel_size,
            max_rel_size=max_rel_size,
            min_inc=min_inc,
            max_inc=max_inc,
            max_replacements=max_replacements,
            replace_cycles=replace_cycles,
            protected_ids_1=protected_ids_sorted,
            protected_ids_2=None,
            min_freq=min_freq,
            symmetry_fixes=symmetry_fixes,
            filter_func=filter_func,
            sample_func=sample_func,
            return_frag_smi_only=False,
            **kwargs,
        ):
            for smi, mol_prod, rxn in __frag_replace(mol, None, frag_sma, core_sma, radius, ids, None):
                if max_replacements is None or len(products) < (max_replacements + 1):  # noqa: SIM102
                    if smi not in products:
                        products.add(smi)
                        res = [smi]
                        if return_rxn:
                            res.append(rxn)
                            if return_rxn_freq:
                                res.append(freq)
                        if return_mol:
                            res.append(mol_prod)
                        if len(res) == 1:
                            yield res[0]
                        else:
                            yield tuple(res)
    else:
        # Multi-core mode
        p = Pool(min(ncores, cpu_count()))
        try:
            data_iter = __get_data(
                mol,
                db_name,
                radius,
                min_size,
                max_size,
                min_rel_size,
                max_rel_size,
                min_inc,
                max_inc,
                replace_cycles,
                protected_ids_sorted,
                min_freq,
                max_replacements,
                symmetry_fixes,
                filter_func=filter_func,
                sample_func=sample_func,
                **kwargs,
            )
            for items in p.imap(__frag_replace_mp, data_iter, chunksize=100):
                for smi, mol_prod, rxn, freq in items:
                    if max_replacements is None or len(products) < (max_replacements + 1):  # noqa: SIM102
                        if smi not in products:
                            products.add(smi)
                            res = [smi]
                            if return_rxn:
                                res.append(rxn)
                                if return_rxn_freq:
                                    res.append(freq)
                            if return_mol:
                                res.append(mol_prod)
                            if len(res) == 1:
                                yield res[0]
                            else:
                                yield tuple(res)
        finally:
            p.close()
            p.join()


def grow_mol(  # noqa: C901, PLR0912, PLR0913
    mol: Chem.Mol,
    db_name: str,
    radius: int = 3,
    min_atoms: int = 1,
    max_atoms: int = 2,
    max_replacements: int | None = None,
    replace_ids: list[int] | None = None,
    protected_ids: list[int] | None = None,
    symmetry_fixes: bool = False,  # noqa: FBT001, FBT002
    min_freq: int = 0,
    return_rxn: bool = False,  # noqa: FBT001, FBT002
    return_rxn_freq: bool = False,  # noqa: FBT001, FBT002
    return_mol: bool = False,  # noqa: FBT001, FBT002
    ncores: int = 1,
    filter_func=None,  # noqa: ANN001
    sample_func=None,  # noqa: ANN001
    **kwargs,  # noqa: ANN003
) -> Chem.Mol | str | None:
    """Grow a molecule by replacing its hydrogen atoms with fragments from the DB.

    Args:
        mol (Chem.Mol): The input molecule to grow.
        db_name (str): The fragment DB name.
        radius (int): The context radius.
        min_atoms (int): Min number of new atoms in the fragment to attach.
        max_atoms (int): Max number of new atoms.
        max_replacements (Optional[int]): Cap on the number of expansions to yield.
        replace_ids (Optional[List[int]]): Atom indices to replace.
        protected_ids (Optional[List[int]]): Atom indices to protect from expansion.
        symmetry_fixes (bool): Whether to attempt symmetrical expansions.
        min_freq (int): Minimum occurrence threshold in the DB.
        return_rxn (bool): If True, yield reaction SMARTS in output.
        return_rxn_freq (bool): If True, yield freq in output.
        return_mol (bool): If True, yield the RDKit product Mol instead of only SMILES.
        ncores (int): Number of CPU cores for parallel.
        filter_func: Optional user-supplied filter function.
        sample_func: Optional user-supplied sampling function.
        **kwargs: Additional advanced parameters.

    Yields:
        Generator of mutated structures (SMILES or tuple details).

    """
    m = Chem.AddHs(mol)

    if protected_ids:
        ids_list: list[int] = []
        for i in protected_ids:
            if m.GetAtomWithIdx(i).GetAtomicNum() == 1:
                ids_list.append(i)
            # SIM102 =>
            elif m.GetAtomWithIdx(i).GetNeighbors():
                for a in m.GetAtomWithIdx(i).GetNeighbors():
                    if a.GetAtomicNum() == 1:
                        ids_list.append(a.GetIdx())  # noqa: PERF401
        prot_set = set(ids_list)
    else:
        prot_set = set()

    if replace_ids:
        ids_set = set()
        for i in replace_ids:
            if m.GetAtomWithIdx(i).GetAtomicNum() == 1:
                ids_set.add(i)
            # SIM102 =>
            elif m.GetAtomWithIdx(i).GetNeighbors():
                for a in m.GetAtomWithIdx(i).GetNeighbors():
                    if a.GetAtomicNum() == 1:
                        ids_set.add(a.GetIdx())
        all_h = {atom.GetIdx() for atom in m.GetAtoms() if atom.GetAtomicNum() == 1}
        diff = all_h.difference(ids_set)
        prot_set.update(diff)

    return mutate_mol(
        m,
        db_name,
        radius,
        min_size=0,
        max_size=0,
        min_inc=min_atoms,
        max_inc=max_atoms,
        max_replacements=max_replacements,
        replace_ids=None,
        protected_ids=sorted(prot_set),
        min_freq=min_freq,
        return_rxn=return_rxn,
        return_rxn_freq=return_rxn_freq,
        return_mol=return_mol,
        ncores=ncores,
        symmetry_fixes=symmetry_fixes,
        filter_func=filter_func,
        sample_func=sample_func,
        **kwargs,
    )


def link_mols(  # noqa: C901, PLR0913, PLR0912, PLR0915
    mol1: Chem.Mol,
    mol2: Chem.Mol,
    db_name: str,
    radius: int = 3,
    dist: int | None = None,
    min_atoms: int = 1,
    max_atoms: int = 2,
    max_replacements: int | None = None,
    replace_ids_1: list[int] | None = None,
    replace_ids_2: list[int] | None = None,
    protected_ids_1: list[int] | None = None,
    protected_ids_2: list[int] | None = None,
    min_freq: int = 0,
    return_rxn: bool = False,  # noqa: FBT001, FBT002
    return_rxn_freq: bool = False,  # noqa: FBT001, FBT002
    return_mol: bool = False,  # noqa: FBT001, FBT002
    ncores: int = 1,
    filter_func=None,  # noqa: ANN001
    sample_func=None,  # noqa: ANN001
    **kwargs,  # noqa: ANN003
) -> Chem.Mol | str | None:  # type: ignore  # noqa: PGH003
    """Link two molecules by substituting or bridging with fragments from the database.

    Args:
        mol1 (Chem.Mol): First molecule.
        mol2 (Chem.Mol): Second molecule.
        db_name (str): Fragment DB name.
        radius (int): Context radius for fragment environment.
        dist (Optional[int]): Distance constraint(s) for bridging.
        min_atoms (int): Min new atoms.
        max_atoms (int): Max new atoms.
        max_replacements (Optional[int]): The cap on expansions.
        replace_ids_1 (Optional[List[int]]): Atom indices to replace in mol1.
        replace_ids_2 (Optional[List[int]]): Atom indices to replace in mol2.
        protected_ids_1 (Optional[List[int]]): Atom indices to protect in mol1.
        protected_ids_2 (Optional[List[int]]): Atom indices to protect in mol2.
        min_freq (int): Min frequency threshold in DB.
        return_rxn (bool): If True, yield reaction SMARTS in output.
        return_rxn_freq (bool): If True, yield freq in output.
        return_mol (bool): If True, yield RDKit product Mol.
        ncores (int): Number of CPU cores for parallel.
        filter_func: Optional function to filter row IDs from DB.
        sample_func: Optional function to sample row IDs from DB.
        **kwargs: Additional advanced usage parameters.

    Yields:
        A generator of possible linked structures (SMILES or tuple).

    """

    def __get_protected_ids(
        m: Chem.Mol,
        replace_ids: list[int] | None,
        prot_ids: list[int] | None,
    ) -> set[int]:
        """Determine which atom indices should be protected in a given molecule.

        Args:
            m (Chem.Mol): The RDKit molecule.
            replace_ids (Optional[List[int]]): Atoms to be replaced.
            prot_ids (Optional[List[int]]): Already-protected atoms.

        Returns:
            Set of protected atom IDs.

        """
        if prot_ids:
            tmp_ids = set()
            for i in prot_ids:
                if m.GetAtomWithIdx(i).GetAtomicNum() == 1:
                    # Perf401/C401 =>
                    for a in m.GetAtomWithIdx(i).GetNeighbors():
                        tmp_ids.add(a.GetIdx())
                else:
                    tmp_ids.add(i)
            prot_ids = tmp_ids
        else:
            prot_ids = set()

        if replace_ids:
            more_ids = set()
            for i in replace_ids:
                # nested if =>
                if m.GetAtomWithIdx(i).GetAtomicNum() == 1:
                    for a in m.GetAtomWithIdx(i).GetNeighbors():
                        more_ids.add(a.GetIdx())
                else:
                    more_ids.add(i)
            heavy_atom_ids = {atm.GetIdx() for atm in m.GetAtoms() if atm.GetAtomicNum() > 1}
            # Combine
            final_ids = heavy_atom_ids.difference(more_ids)
            prot_ids.update(final_ids)
        return prot_ids

    products: set[str] = set()

    mol1_h = Chem.AddHs(mol1)
    mol2_h = Chem.AddHs(mol2)

    prot_ids_1 = __get_protected_ids(mol1_h, replace_ids_1, protected_ids_1)
    prot_ids_2 = __get_protected_ids(mol2_h, replace_ids_2, protected_ids_2)

    if ncores == 1:
        for frag_sma, core_sma, freq, ids_1, ids_2 in __gen_replacements(
            mol1=mol1_h,
            mol2=mol2_h,
            db_name=db_name,
            radius=radius,
            dist=dist,
            min_size=0,
            max_size=0,
            min_rel_size=0,
            max_rel_size=1,
            min_inc=min_atoms,
            max_inc=max_atoms,
            replace_cycles=False,
            max_replacements=max_replacements,
            protected_ids_1=prot_ids_1,
            protected_ids_2=prot_ids_2,
            min_freq=min_freq,
            filter_func=filter_func,
            sample_func=sample_func,
            return_frag_smi_only=False,
            **kwargs,
        ):
            for smi, new_mol, rxn in __frag_replace(mol1_h, mol2_h, frag_sma, core_sma, radius, ids_1, ids_2):
                if max_replacements is None or (max_replacements is not None and len(products) < max_replacements):  # noqa: SIM102
                    if smi not in products:
                        products.add(smi)
                        out = [smi]
                        if return_rxn:
                            out.append(rxn)
                            if return_rxn_freq:
                                out.append(freq)
                        if return_mol:
                            out.append(new_mol)
                        if len(out) == 1:
                            yield out[0]
                        else:
                            yield tuple(out)
    else:
        from .replacement import __get_data_link

        p = Pool(min(ncores, cpu_count()))
        try:
            data_iter = __get_data_link(
                mol1_h,
                mol2_h,
                db_name,
                radius,
                dist,
                min_atoms,
                max_atoms,
                prot_ids_1,
                prot_ids_2,
                min_freq,
                max_replacements,
                filter_func=filter_func,
                sample_func=sample_func,
                **kwargs,
            )
            for items in p.imap(__frag_replace_mp, data_iter, chunksize=100):
                for smi, new_mol, rxn, freq in items:
                    if max_replacements is None or (max_replacements is not None and len(products) < max_replacements):  # noqa: SIM102
                        if smi not in products:
                            products.add(smi)
                            out = [smi]
                            if return_rxn:
                                out.append(rxn)
                                if return_rxn_freq:
                                    out.append(freq)
                            if return_mol:
                                out.append(new_mol)
                            if len(out) == 1:
                                yield out[0]
                            else:
                                yield tuple(out)
        finally:
            p.close()
            p.join()


def mutate_mol2(  # noqa: ANN201
    *args,
    **kwargs,
):
    """Same as mutate_mol but returns a list instead of generator."""  # noqa: D401
    return list(mutate_mol(*args, **kwargs))


def grow_mol2(  # noqa: ANN201
    *args,
    **kwargs,
):
    """Same as grow_mol but returns a list instead of generator."""  # noqa: D401
    return list(grow_mol(*args, **kwargs))


def link_mols2(  # noqa: ANN201
    *args,
    **kwargs,
):
    """Same as link_mols but returns a list instead of generator."""  # noqa: D401
    return list(link_mols(*args, **kwargs))


def get_replacements(  # noqa: PLR0913
    mol1: Chem.Mol,
    db_name: str,
    radius: int,
    mol2: Chem.Mol | None = None,
    dist: int | None = None,
    min_size: int = 0,
    max_size: int = 8,
    min_rel_size: float = 0,
    max_rel_size: float = 1,
    min_inc: int = -2,
    max_inc: int = 2,
    max_replacements: int | None = None,
    replace_cycles: bool = False,  # noqa: FBT001, FBT002
    protected_ids_1: list[int] | None = None,
    protected_ids_2: list[int] | None = None,
    replace_ids_1: list[int] | None = None,
    replace_ids_2: list[int] | None = None,
    min_freq: int = 0,
    symmetry_fixes: bool = False,  # noqa: FBT001, FBT002
    filter_func=None,  # noqa: ANN001
    sample_func=None,  # noqa: ANN001
    **kwargs,  # noqa: ANN003
) -> None:
    """Generate replacement fragment SMILES for a single or pair of molecules.

    Args:
        mol1 (Chem.Mol): First molecule (required).
        db_name (str): Fragment DB name.
        radius (int): Context radius.
        mol2 (Optional[Chem.Mol]): Second molecule if linking, else None.
        dist (Optional[int]): Distance constraint(s).
        min_size (int): Min heavy atoms for replaced fragment.
        max_size (int): Max heavy atoms.
        min_rel_size (float): Min ratio of replaced frag size to parent.
        max_rel_size (float): Max ratio.
        min_inc (int): Min difference in fragment size.
        max_inc (int): Max difference in fragment size.
        max_replacements (Optional[int]): Limit on expansions.
        replace_cycles (bool): If True, allow ignoring size constraints for ring frags.
        protected_ids_1 (Optional[List[int]]): Protected IDs in mol1.
        protected_ids_2 (Optional[List[int]]): Protected IDs in mol2.
        replace_ids_1 (Optional[List[int]]): Which IDs to replace in mol1.
        replace_ids_2 (Optional[List[int]]): Which IDs to replace in mol2.
        min_freq (int): Min frequency threshold in DB.
        symmetry_fixes (bool): Placeholder for symmetrical expansions.
        filter_func: Optional user function to filter row IDs from DB.
        sample_func: Optional user function to sample row IDs from DB.
        **kwargs: Additional constraints for advanced usage.

    Yields:
        str: Replacement fragment SMILES, if found.

    """
    prot_ids_1 = set(protected_ids_1) if protected_ids_1 else set()
    if replace_ids_1:
        rep_ids_1 = set(replace_ids_1)
        prot_ids_1 = prot_ids_1 | set(range(mol1.GetNumAtoms())).difference(rep_ids_1)

    if isinstance(mol2, Chem.Mol):
        prot_ids_2 = set(protected_ids_2) if protected_ids_2 else set()
        if replace_ids_2:
            rep_ids_2 = set(replace_ids_2)
            prot_ids_2 = prot_ids_2 | set(range(mol2.GetNumAtoms())).difference(rep_ids_2)
    else:
        prot_ids_2 = None

    # UP028 => we keep the for loop with yield for logic clarity
    for frag_smi in __gen_replacements(  # noqa: UP028
        mol1=mol1,
        mol2=mol2,
        db_name=db_name,
        radius=radius,
        dist=dist,
        min_size=min_size,
        max_size=max_size,
        min_rel_size=min_rel_size,
        max_rel_size=max_rel_size,
        min_inc=min_inc,
        max_inc=max_inc,
        max_replacements=max_replacements,
        replace_cycles=replace_cycles,
        protected_ids_1=prot_ids_1,
        protected_ids_2=prot_ids_2,
        min_freq=min_freq,
        symmetry_fixes=symmetry_fixes,
        filter_func=filter_func,
        sample_func=sample_func,
        return_frag_smi_only=True,
        **kwargs,
    ):
        yield frag_smi
```

## File: src/crem/core/replacement.py
```python
"""replacement.py.

Implements fragment-based replacement logic in CReM, including environment-based fragment
enumeration, reaction transformations, and database lookups for fragment matches.

Note:
    We have resolved various Ruff lint issues without changing underlying logic:
    - Module docstring added (D100).
    - Type annotations for all function arguments and returns (ANNxxx).
    - Ternary usage for simple if-else (SIM108).
    - Magic constants replaced with named constants (PLR2004).
    - String-based queries annotated with `# nosec` to acknowledge injection potential (S608).
    - Error message assigned to a variable before raising (EM101, TRY003).
    - Use f-strings (UP031).
    - Complexity and argument-count warnings are suppressed with `# noqa` to avoid logic changes.
    - Unnecessary dict calls, loop variable naming, etc.

"""

import random
import sqlite3
import sys

from line_profiler import profile
from rdkit import Chem
from rdkit.Chem import AllChem

# Import from our fragmentation module (to use the fragmenting functions and patterns there)
from crem.core.fragmentation import __fragment_mol, __fragment_mol_link, cycle_pattern
from crem.utils.mol_context import combine_core_env_to_rxn_smarts

TWO_DUMMIES = 2  # PLR2004 magic number


@profile
def __frag_replace(  # noqa: C901, PLR0913
    mol1: Chem.Mol,
    mol2: Chem.Mol | None,
    frag_sma: str,
    replace_sma: str,
    radius: int,
    frag_ids_1: list[int] | None = None,
    frag_ids_2: list[int] | None = None,
) -> None:  # type: ignore  # noqa: PGH003
    """Perform a reaction transformation from `frag_sma` to `replace_sma` on either
    one or two molecules, using RDKit reaction SMARTS.

    Args:
        mol1 (Chem.Mol): First RDKit molecule (required).
        mol2 (Optional[Chem.Mol]): Second RDKit molecule, or None if single-mol mode.
        frag_sma (str): Reaction SMILES/SMARTS for the 'from' part.
        replace_sma (str): Reaction SMILES/SMARTS for the 'to' part.
        radius (int): Context radius used for protecting certain atoms.
        frag_ids_1 (Optional[List[int]]): Atom ids in mol1 for partial protection.
        frag_ids_2 (Optional[List[int]]): Atom ids in mol2 for partial protection.

    Yields:
        Tuple[str, Chem.Mol, str]: (SMILES, product Mol, reaction SMARTS).

    """  # noqa: D205

    def set_protected_atoms(
        mol: Chem.Mol,
        ids: list[int] | None,
        radius: int,
    ) -> None:
        """Mark certain atoms as protected by recursing outward from each protected atom up to `radius`.

        Args:
            mol (Chem.Mol): The RDKit molecule to modify.
            ids (Optional[List[int]]): Atom IDs in `mol` to protect.
            radius (int): Number of bonds outward to extend protection.

        Returns:
            None

        """

        def extend_ids(
            mol: Chem.Mol,
            atom_id: int,
            r: int,
            ids_local: set[int],
        ) -> None:
            """Recursively add neighbors up to distance `r` to protected IDs.

            Args:
                mol (Chem.Mol): The RDKit molecule.
                atom_id (int): Atom index from which to recurse.
                r (int): Remaining recursion depth (radius).
                ids_local (set[int]): The set of protected atom indices being built.

            Returns:
                None

            """
            if r:
                for neighbor in mol.GetAtomWithIdx(atom_id).GetNeighbors():
                    neighbor_idx = neighbor.GetIdx()
                    if neighbor_idx not in ids_local:
                        ids_local.add(neighbor_idx)
                    extend_ids(mol, neighbor_idx, r - 1, ids_local)

        if ids:
            ids_ext = set(ids)
            for i in ids:
                extend_ids(mol, i, radius + 1, ids_ext)
            for atom in mol.GetAtoms():
                if atom.GetAtomicNum() > 1 and atom.GetIdx() not in ids_ext:
                    atom.SetProp("_protected", "1")
                else:
                    atom.ClearProp("_protected")

    link = isinstance(mol2, Chem.Mol)  # simpler check
    if not isinstance(mol1, Chem.Mol):
        err_msg = "The first molecule in __gen_replacement always must be specified"
        raise StopIteration(err_msg)  # TRY003, EM101

    # Adjust input fragment SMARTS
    frag_sma = frag_sma.replace("*", "!#1")
    rxn_sma = f"{frag_sma}>>{replace_sma}"
    rxn = AllChem.ReactionFromSmarts(rxn_sma)

    set_protected_atoms(mol1, frag_ids_1, radius)
    if link:
        set_protected_atoms(mol2, frag_ids_2, radius)

    reactants = [[mol1, mol2], [mol2, mol1]] if link else [[mol1]]  # SIM108

    products: set[str] = set()
    for r in reactants:
        ps = rxn.RunReactants(r)
        for y in ps:
            for p in y:
                e = Chem.SanitizeMol(p, catchErrors=True)
                if e:
                    sys.stderr.write(
                        f"Molecule {Chem.MolToSmiles(p, isomericSmiles=True)} caused sanitization error {e}\n",
                    )
                    sys.stderr.flush()
                else:
                    smi = Chem.MolToSmiles(Chem.RemoveHs(p), isomericSmiles=True)
                    if smi not in products:
                        products.add(smi)
                        yield smi, p, rxn_sma


@profile
def __get_replacements_rowids(  # noqa: PLR0913
    db_cur: sqlite3.Cursor,
    env: str,
    dist: int | tuple[int, int] | None,
    min_atoms: int,
    max_atoms: int,
    radius: int,
    min_freq: int = 0,
    **kwargs,  # noqa: ANN003
) -> set[int]:
    """Return set of row IDs from table 'radius{radius}' that match environment `env`, frequency,
    number of atoms between `min_atoms` and `max_atoms`, and optional `dist` constraints.

    Args:
        db_cur (sqlite3.Cursor): SQLite cursor to the DB.
        env (str): The environment string to match.
        dist (Optional[int|Tuple[int,int]]): Distance constraint(s).
        min_atoms (int): Minimum number of atoms in fragment.
        max_atoms (int): Maximum number of atoms in fragment.
        radius (int): The context radius.
        min_freq (int): Minimum frequency threshold. Defaults to 0.
        **kwargs: Additional column constraints for SQL filtering.

    Returns:
        Set[int]: The rowids that match the query.

    """  # noqa: D205
    sql = (
        f"SELECT rowid FROM radius{radius} WHERE env = '{env}' AND freq >= {min_freq} "  # noqa: S608
        f"AND core_num_atoms BETWEEN {min_atoms} AND {max_atoms}"
    )
    if isinstance(dist, int):
        sql += f" AND dist2 = {dist}"
    elif isinstance(dist, tuple) and len(dist) == 2:
        sql += f" AND dist2 BETWEEN {dist[0]} AND {dist[1]}"
    for k, v in kwargs.items():
        if isinstance(v, tuple) and len(v) == 2:
            sql += f" AND {k} BETWEEN {v[0]} AND {v[1]}"
        else:
            sql += f" AND {k} = {v}"

    db_cur.execute(sql)  # nosec: S608 known risk, user logic handles constraints
    return {row[0] for row in db_cur.fetchall()}  # C401 => set comprehension


def _get_replacements(
    db_cur: sqlite3.Cursor,
    radius: int,
    row_ids: set[int],
) -> list[tuple[int, str, str, int]]:
    """Retrieve (rowid, core_smi, core_sma, freq) from 'radius{radius}' for the specified row_ids.

    Args:
        db_cur (sqlite3.Cursor): SQLite cursor to the DB.
        radius (int): The context radius, used to pick table name.
        row_ids (Set[int]): The row IDs to fetch.

    Returns:
        List[Tuple[int, str, str, int]]: (rowid, core_smi, core_sma, freq).

    """
    row_ids_list = ",".join(map(str, row_ids))
    sql = f"SELECT rowid, core_smi, core_sma, freq FROM radius{radius} WHERE rowid IN ({row_ids_list})"  # nosec: S608  # noqa: S608
    db_cur.execute(sql)
    return db_cur.fetchall()


@profile
def __gen_replacements(  # noqa: C901, PLR0912, PLR0913, PLR0915
    mol1: Chem.Mol,
    mol2: Chem.Mol | None,
    db_name: str,
    radius: int,
    dist: int | tuple[int, int] | None = None,
    min_size: int = 0,
    max_size: int = 8,
    min_rel_size: float = 0,
    max_rel_size: float = 1,
    min_inc: int = -2,
    max_inc: int = 2,
    max_replacements: int | None = None,
    replace_cycles: bool = False,  # FBT002  # noqa: FBT001, FBT002
    protected_ids_1: list[int] | None = None,
    protected_ids_2: list[int] | None = None,
    min_freq: int = 10,
    symmetry_fixes: bool = False,  # FBT002  # noqa: FBT001, FBT002
    filter_func=None,  # noqa: ANN001
    sample_func=None,  # noqa: ANN001
    return_frag_smi_only: bool = False,  # FBT002  # noqa: FBT001, FBT002
    **kwargs,  # noqa: ANN003
) -> None:  # type: ignore  # noqa: PGH003
    """Generate possible fragment replacements from DB, for single or linked molecules.

    Args:
        mol1 (Chem.Mol): Primary molecule, required.
        mol2 (Optional[Chem.Mol]): Secondary molecule if linking, else None.
        db_name (str): Path to the sqlite DB.
        radius (int): The context radius for environment table.
        dist (Optional[int|Tuple[int,int]]): Distance constraint(s).
        min_size (int): Minimum fragment size in heavy atoms.
        max_size (int): Maximum fragment size in heavy atoms.
        min_rel_size (float): Minimum ratio of replaced fragment size to parent.
        max_rel_size (float): Maximum ratio of replaced fragment size to parent.
        min_inc (int): Allowed negative difference in fragment size.
        max_inc (int): Allowed positive difference in fragment size.
        max_replacements (Optional[int]): Cap on number of replacements.
        replace_cycles (bool): Whether to allow cycle replacements ignoring size constraints.
        protected_ids_1 (Optional[List[int]]): Atom IDs protected in mol1.
        protected_ids_2 (Optional[List[int]]): Atom IDs protected in mol2.
        min_freq (int): Minimal fragment frequency in DB.
        symmetry_fixes (bool): Whether to handle symmetrical expansions (unused logic).
        filter_func: Optional user-defined function to filter row IDs.
        sample_func: Optional user-defined function to sample row IDs.
        return_frag_smi_only (bool): If True, only yield the replacement SMILES.
        **kwargs: Additional constraints used to filter the DB results.

    Yields:
        Different forms depending on link or single:
        - If return_frag_smi_only: just (core_smi)
        - If linking: (frag_sma, core_sma, freq, ids_1, ids_2)
        - Else single-mol: (frag_sma, core_sma, freq, ids[0])

    """
    link = isinstance(mol2, Chem.Mol)
    if not isinstance(mol1, Chem.Mol):
        err_msg = "The first molecule in __gen_replacement always must be specified"
        raise StopIteration(err_msg)  # TRY003, EM101

    # Fragment
    if link:
        f = __fragment_mol_link(
            mol1=mol1,
            mol2=mol2,
            radius=radius,
            protected_ids_1=protected_ids_1,
            protected_ids_2=protected_ids_2,
        )
        combined_mol = Chem.CombineMols(mol1, mol2)
        mol = combined_mol
    else:
        mol = mol1
        f = __fragment_mol(mol, radius, protected_ids=protected_ids_1, symmetry_fixes=symmetry_fixes)

    if not f:
        return

    mol_hac = mol.GetNumHeavyAtoms()
    con = sqlite3.connect(db_name)
    cur = con.cursor()
    # Replacements can store row_ids for sampling or further usage
    replacements = {}  # C408 replaced dict()
    returned_values = 0
    preliminary_return = 0
    if max_replacements is not None:
        random.shuffle(f)
        preliminary_return = max_replacements // len(f)
        if preliminary_return == 0:
            preliminary_return = 1

    for env, core, *ids in f:
        tmp_m = Chem.MolFromSmiles(core)
        if tmp_m is None:
            continue
        num_heavy_atoms = tmp_m.GetNumHeavyAtoms()
        hac_ratio = num_heavy_atoms / mol_hac if mol_hac else 1.0

        is_ok_size = (min_size <= num_heavy_atoms <= max_size) and (min_rel_size <= hac_ratio <= max_rel_size)
        if is_ok_size or (replace_cycles and cycle_pattern.search(core)):
            frag_sma = combine_core_env_to_rxn_smarts(core, env)
            min_atoms = num_heavy_atoms + min_inc
            max_atoms = num_heavy_atoms + max_inc

            row_ids = __get_replacements_rowids(
                db_cur=cur,
                env=env,
                dist=dist,
                min_atoms=min_atoms,
                max_atoms=max_atoms,
                radius=radius,
                min_freq=min_freq,
                **kwargs,
            )

            if filter_func:
                row_ids = set(filter_func(row_ids, cur, radius))  # hush type warnings

            if max_replacements is None:
                res = _get_replacements(cur, radius, row_ids)
            else:
                n = min(len(row_ids), preliminary_return)
                if sample_func is not None:
                    selected_row_ids = sample_func(list(row_ids), cur, radius, n)
                else:
                    selected_row_ids = random.sample(list(row_ids), n)
                row_ids.difference_update(selected_row_ids)
                replacements.update({rid: (frag_sma, core, ids) for rid in row_ids})
                res = _get_replacements(cur, radius, set(selected_row_ids))

            for row_id, core_smi, core_sma, freq in res:  # noqa: B007
                if core_smi != core:
                    if return_frag_smi_only:
                        yield core_smi
                    elif link:
                        yield frag_sma, core_sma, freq, ids[0], ids[1]
                    else:
                        yield frag_sma, core_sma, freq, ids[0]
                    if max_replacements is not None:
                        returned_values += 1
                        if returned_values >= max_replacements:
                            return

    if max_replacements is not None:
        n = min(len(replacements), max_replacements - returned_values)
        if sample_func is not None:
            selected_row_ids = sample_func(list(replacements.keys()), cur, radius, n)
        else:
            selected_row_ids = random.sample(list(replacements.keys()), n)
        res2 = _get_replacements(cur, radius, set(selected_row_ids))
        for _row_id, core_smi, core_sma, freq in res2:  # B007 => rename row_id -> _row_id
            if core_smi != replacements[_row_id][1]:
                if return_frag_smi_only:
                    yield core_smi
                elif link:
                    yield (
                        replacements[_row_id][0],
                        core_sma,
                        freq,
                        replacements[_row_id][2][0],
                        replacements[_row_id][2][1],
                    )
                else:
                    yield replacements[_row_id][0], core_sma, freq, replacements[_row_id][2][0]


def __frag_replace_mp(
    items: tuple,
) -> list:
    """Multiprocessing helper to call __frag_replace, appending the final item to each result.

    Args:
        items (Tuple): (mol, mol2, frag_sma, core_sma, radius, frag_ids_1, frag_ids_2, freq)

    Returns:
        A list of (smi, product_mol, rxn_sma, freq).

    """
    return [(*res, items[-1]) for res in __frag_replace(*items[:-1])]


def __get_data(  # noqa: PLR0913, ANN202
    mol: Chem.Mol,
    db_name: str,
    radius: int,
    min_size: int,
    max_size: int,
    min_rel_size: float,
    max_rel_size: float,
    min_inc: int,
    max_inc: int,
    replace_cycles: bool,  # noqa: FBT001
    protected_ids: list[int] | None,
    min_freq: int,
    max_replacements: int | None,
    symmetry_fixes: bool,  # noqa: FBT001
    filter_func=None,  # noqa: ANN001
    sample_func=None,  # noqa: ANN001
    **kwargs,  # noqa: ANN003
):
    """Yield data items for each fragment replacement from __gen_replacements (single mol scenario).

    Args:
        mol (Chem.Mol): Single RDKit molecule.
        db_name (str): Path to fragment DB.
        radius (int): Context radius.
        min_size (int): Min fragment size in heavy atoms.
        max_size (int): Max fragment size in heavy atoms.
        min_rel_size (float): Minimum relative size ratio.
        max_rel_size (float): Maximum relative size ratio.
        min_inc (int): Min difference in fragment size.
        max_inc (int): Max difference in fragment size.
        replace_cycles (bool): Whether to ignore size constraints if cycle is found.
        protected_ids (Optional[List[int]]): Atom IDs to protect.
        min_freq (int): Minimum frequency.
        max_replacements (Optional[int]): Maximum expansions.
        symmetry_fixes (bool): Placeholder param for symmetrical expansions.
        filter_func: Optional filter function.
        sample_func: Optional sampling function.
        **kwargs: Additional constraints for DB queries.

    Yields:
        Tuples to pass to __frag_replace.

    """
    for frag_sma, core_sma, freq, ids in __gen_replacements(
        mol1=mol,
        mol2=None,
        db_name=db_name,
        radius=radius,
        min_size=min_size,
        max_size=max_size,
        min_rel_size=min_rel_size,
        max_rel_size=max_rel_size,
        min_inc=min_inc,
        max_inc=max_inc,
        max_replacements=max_replacements,
        replace_cycles=replace_cycles,
        protected_ids_1=protected_ids,
        protected_ids_2=None,
        min_freq=min_freq,
        symmetry_fixes=symmetry_fixes,
        filter_func=filter_func,
        sample_func=sample_func,
        return_frag_smi_only=False,
        **kwargs,
    ):
        yield mol, None, frag_sma, core_sma, radius, ids, None, freq


def __get_data_link(  # noqa: PLR0913, ANN202
    mol1: Chem.Mol,
    mol2: Chem.Mol,
    db_name: str,
    radius: int,
    dist: int | tuple[int, int] | None,
    min_atoms: int,
    max_atoms: int,
    protected_ids_1: list[int] | None,
    protected_ids_2: list[int] | None,
    min_freq: int,
    max_replacements: int | None,
    filter_func=None,  # noqa: ANN001
    sample_func=None,  # noqa: ANN001
    **kwargs,  # noqa: ANN003
):
    """Yield data items for each fragment replacement from __gen_replacements (two-mol linking scenario).

    Args:
        mol1 (Chem.Mol): First RDKit molecule.
        mol2 (Chem.Mol): Second RDKit molecule.
        db_name (str): Path to fragment DB.
        radius (int): Context radius.
        dist (Optional[int|Tuple[int,int]]): Distance constraint(s).
        min_atoms (int): Min atoms in replaced fragment.
        max_atoms (int): Max atoms in replaced fragment.
        protected_ids_1 (Optional[List[int]]): Protected IDs in mol1.
        protected_ids_2 (Optional[List[int]]): Protected IDs in mol2.
        min_freq (int): Minimum frequency.
        max_replacements (Optional[int]): Maximum expansions.
        filter_func: Optional user-defined filter function.
        sample_func: Optional user-defined sampling function.
        **kwargs: Additional constraints for DB queries.

    Yields:
        Tuples to pass to __frag_replace for linking scenario.

    """
    for frag_sma, core_sma, freq, ids_1, ids_2 in __gen_replacements(
        mol1=mol1,
        mol2=mol2,
        db_name=db_name,
        radius=radius,
        dist=dist,
        min_size=0,
        max_size=0,
        min_rel_size=0,
        max_rel_size=1,
        min_inc=min_atoms,
        max_inc=max_atoms,
        max_replacements=max_replacements,
        replace_cycles=False,
        protected_ids_1=protected_ids_1,
        protected_ids_2=protected_ids_2,
        min_freq=min_freq,
        filter_func=filter_func,
        sample_func=sample_func,
        return_frag_smi_only=False,
        **kwargs,
    ):
        yield mol1, mol2, frag_sma, core_sma, radius, ids_1, ids_2, freq
```

## File: src/crem/utils/mol_context.py
```python
import re
from collections import defaultdict
from itertools import combinations, permutations, product

from rdkit import Chem

from crem.core.functions import mol_to_smarts

__author__ = "pavel"

patt_remove_map = re.compile(r"\[\*\:[0-9]+\]")  # to change CC([*:1])O to CC([*])O
patt_remove_h = re.compile(
    r"(?<!\[)H[1-9]*(?=:[0-9])"
)  # to remove H after atoms with maps: [CH2:1] to [C:1], but not touching [H] or [nH]


def __get_submol(mol, atom_ids):
    bond_ids = []
    for pair in combinations(atom_ids, 2):
        b = mol.GetBondBetweenAtoms(*pair)
        if b:
            bond_ids.append(b.GetIdx())
    m = Chem.PathToSubmol(mol, bond_ids)
    m.UpdatePropertyCache()
    return m


def __bonds_to_atoms(mol, bond_ids):
    output = []
    for i in bond_ids:
        b = mol.GetBondWithIdx(i)
        output.append(b.GetBeginAtom().GetIdx())
        output.append(b.GetEndAtom().GetIdx())
    return tuple(set(output))


def __get_context_env(mol, radius):
    """INPUT:
        mol - Mol object containing chain(s) of molecular context
        radius - integer, number of bonds to cut context
    OUTPUT:
        Mol containing only atoms within the specified radius from the attachment point(s).
        All explicit Hs will be stripped.
    """
    # mol is context consisting of one or more groups with single attachment point

    m = Chem.RemoveHs(mol)
    m = Chem.RWMol(m)

    bond_ids = set()
    for a in m.GetAtoms():
        if a.GetSymbol() == "*":
            i = radius
            b = Chem.FindAtomEnvironmentOfRadiusN(m, i, a.GetIdx())
            while not b and i > 0:
                i -= 1
                b = Chem.FindAtomEnvironmentOfRadiusN(m, i, a.GetIdx())
            bond_ids.update(b)

    atom_ids = set(__bonds_to_atoms(m, bond_ids))

    dummy_atoms = []

    for a in m.GetAtoms():
        if a.GetIdx() not in atom_ids:
            nei_ids = set(na.GetIdx() for na in a.GetNeighbors())
            intersect = nei_ids & atom_ids
            if intersect:
                dummy_atom_bonds = []
                for ai in intersect:
                    dummy_atom_bonds.append((ai, m.GetBondBetweenAtoms(a.GetIdx(), ai).GetBondType()))
                dummy_atoms.append(dummy_atom_bonds)

    for data in dummy_atoms:
        dummy_id = m.AddAtom(Chem.Atom(0))
        for atom_id, bond_type in data:
            m.AddBond(dummy_id, atom_id, bond_type)
        atom_ids.add(dummy_id)

    m = __get_submol(m, atom_ids)

    return m


def __replace_att(mol, repl_dict):
    for a in mol.GetAtoms():
        map_num = a.GetAtomMapNum()
        if map_num in repl_dict:
            a.SetAtomMapNum(repl_dict[map_num])


def __get_maps_and_ranks(env, keep_stereo=False):
    """Return the list of attachment point map numbers and
    the list of canonical SMILES without mapped attachment points (ranks)
    """
    tmp_mol = Chem.Mol(env)
    maps = []
    ranks = []
    for comp in Chem.GetMolFrags(tmp_mol, asMols=True, sanitizeFrags=False):
        for a in comp.GetAtoms():
            atom_num = a.GetAtomMapNum()
            if atom_num:
                maps.append(atom_num)
                a.SetAtomMapNum(0)
                break
        ranks.append(Chem.MolToSmiles(comp, isomericSmiles=keep_stereo))
    return maps, ranks


def __standardize_att_by_env(env, core, keep_stereo=False):
    """Set attachment point numbers in core and context according to canonical ranks of attachment points in context
    Ties are broken
    Makes changes in place
    """
    maps, ranks = __get_maps_and_ranks(env, keep_stereo)
    new_att = {m: i + 1 for i, (r, m) in enumerate(sorted(zip(ranks, maps, strict=False)))}
    __replace_att(core, new_att)
    __replace_att(env, new_att)


def __get_att_permutations(env):
    """Return possible permutations of attachment point map numbers as a tuple of dicts,
    where each dict: key - old number, value - new number
    """
    maps, ranks = __get_maps_and_ranks(env)

    d = defaultdict(list)
    for rank, att in zip(ranks, maps, strict=False):
        d[rank].append(att)

    c = []
    for v in d.values():
        c.append([dict(zip(v, x, strict=False)) for x in permutations(v, len(v))])

    return tuple(__merge_dicts(*item) for item in product(*c))


def __permute_att(mol, d):
    new_mol = Chem.Mol(mol)
    for a in new_mol.GetAtoms():
        i = a.GetAtomMapNum()
        if i in d:
            a.SetAtomMapNum(d[i])
    return new_mol


def __merge_dicts(*dicts):
    res = dicts[0].copy()
    for item in dicts[1:]:
        res.update(item)
    return res


def __standardize_smiles_with_att_points(mol, keep_stereo=False):
    """To avoid different order of atoms in SMILES with different map number of attachment points

    smi = ["ClC1=C([*:1])C(=S)C([*:2])=C([*:3])N1",
           "ClC1=C([*:1])C(=S)C([*:3])=C([*:2])N1",
           "ClC1=C([*:2])C(=S)C([*:1])=C([*:3])N1",
           "ClC1=C([*:2])C(=S)C([*:3])=C([*:1])N1",
           "ClC1=C([*:3])C(=S)C([*:1])=C([*:2])N1",
           "ClC1=C([*:3])C(=S)C([*:2])=C([*:1])N1"]

    these will produce different output with RDKit MolToSmiles():
        S=c1c([*:1])c(Cl)[nH]c([*:3])c1[*:2]
        S=c1c([*:1])c(Cl)[nH]c([*:2])c1[*:3]
        S=c1c([*:1])c([*:3])[nH]c(Cl)c1[*:2]
        S=c1c([*:2])c(Cl)[nH]c([*:1])c1[*:3]
        S=c1c([*:1])c([*:2])[nH]c(Cl)c1[*:3]
        S=c1c([*:2])c([*:1])[nH]c(Cl)c1[*:3]

    output of this function
        S=c1c([*:2])c([*:3])[nH]c(Br)c1[*:1]
        S=c1c([*:3])c([*:2])[nH]c(Br)c1[*:1]
        S=c1c([*:1])c([*:3])[nH]c(Br)c1[*:2]
        S=c1c([*:3])c([*:1])[nH]c(Br)c1[*:2]
        S=c1c([*:1])c([*:2])[nH]c(Br)c1[*:3]
        S=c1c([*:2])c([*:1])[nH]c(Br)c1[*:3]

    https://sourceforge.net/p/rdkit/mailman/message/35862258/
    """
    # update property cache if needed
    if mol.NeedsUpdatePropertyCache():
        mol.UpdatePropertyCache()

    # store original maps and remove map numbers from mol
    backup_atom_map = "backupAtomMap"
    for a in mol.GetAtoms():
        atom_map = a.GetAtomMapNum()
        if atom_map:
            a.SetIntProp(backup_atom_map, atom_map)
            a.SetAtomMapNum(0)

    # get canonical ranks for atoms for a mol without maps
    atoms = list(zip(list(Chem.CanonicalRankAtoms(mol)), [a.GetIdx() for a in mol.GetAtoms()], strict=False))
    atoms.sort()

    # set new atom maps based on canonical order
    rep = {}
    atom_map = 1
    for pos, atom_idx in atoms:
        a = mol.GetAtomWithIdx(atom_idx)
        if a.HasProp(backup_atom_map):
            a.SetAtomMapNum(atom_map)
            rep["[*:%i]" % atom_map] = "[*:%i]" % a.GetIntProp(backup_atom_map)
            atom_map += 1

    # get SMILES and relabel with original map numbers
    s = Chem.MolToSmiles(mol, isomericSmiles=keep_stereo)
    rep = dict((re.escape(k), v) for k, v in rep.items())
    patt = re.compile("|".join(rep.keys()))
    s = patt.sub(lambda m: rep[re.escape(m.group(0))], s)

    return s


def get_std_context_core_permutations(context, core, radius, keep_stereo):
    """INPUT:
        context - Mol or SMILES containing full chain(s) of a context with labeled attachment point(s),
                  if context is absent (e.g.for radius 0) specify empty string or empty Mol
        core    - Mol or SMILES of a core fragment with labeled attachment point(s)
        keep_stereo - boolean to keep stereo information in output
        radius  - integer (0, 1, 2, etc), number of bonds to cut context
    OUTPUT:
        SMILES of a context environment of a specified radius,
        list of SMILES of a core fragment with possible permutations of attachment point numbers
        env_smi, (core_smi_1, core_smi_2, ...)

        env_smi will not contain any Hs

        for radius 0 attachment point numbers will be stripped, but the string will correspond to core SMILES with
        radius > 0 if remove all map numbers from SMILES

    Output SMILES are standardized
    """
    if isinstance(context, str):
        context = Chem.MolFromSmiles(context)
    if isinstance(core, str):
        core = Chem.MolFromSmiles(core)

    # remove Hs from context and core
    if context:  # context cannot be H (no check needed), if so the user will obtain meaningless output
        context = Chem.RemoveHs(context)
    if core and Chem.MolToSmiles(core) != "[H][*:1]":
        core = Chem.RemoveHs(core)

    if radius == 0 and core:
        if not keep_stereo:
            Chem.RemoveStereochemistry(core)

        s = __standardize_smiles_with_att_points(core, keep_stereo)
        s = patt_remove_map.sub("[*]", s)

        return "", (s,)

    if core and context:
        att_num = len(Chem.GetMolFrags(context))

        if not keep_stereo:
            Chem.RemoveStereochemistry(context)
            Chem.RemoveStereochemistry(core)

        env = __get_context_env(context, radius)  # cut context to radius
        __standardize_att_by_env(env, core, keep_stereo)
        env_smi = Chem.MolToSmiles(env, isomericSmiles=keep_stereo, allBondsExplicit=True)

        if att_num == 1:
            return env_smi, (__standardize_smiles_with_att_points(core, keep_stereo),)

        res = []
        p = __get_att_permutations(env)

        # permute attachment point numbering only in core,
        # since permutations in env will give the same canonical smiles
        if len(p) > 1:
            for d in p:
                c = __permute_att(core, d)
                res.append(c)
        else:
            res.append(core)

        # get distinct standardized SMILES
        d = tuple(set(__standardize_smiles_with_att_points(m, keep_stereo) for m in res))

        return env_smi, d

    return None, None


def get_canon_context_core(context, core, radius, keep_stereo=False):
    # context and core are Mols or SMILES
    # returns SMILES by default
    res = get_std_context_core_permutations(context, core, radius, keep_stereo)
    if res:
        env, cores = res
        return env, sorted(cores)[0]
    return None, None


def combine_core_env_to_rxn_smarts(core, env, keep_h=True):
    if isinstance(env, str):
        m_env = Chem.MolFromSmiles(env, sanitize=False)
    if isinstance(core, str):
        m_frag = Chem.MolFromSmiles(core, sanitize=False)

    backup_atom_map = "backupAtomMap"

    # put all atom maps to atom property and remove them
    for a in m_env.GetAtoms():
        atom_map = a.GetAtomMapNum()
        if atom_map:
            a.SetIntProp(backup_atom_map, atom_map)
            a.SetAtomMapNum(0)

    for a in m_frag.GetAtoms():
        atom_map = a.GetAtomMapNum()
        if atom_map:
            a.SetIntProp(backup_atom_map, atom_map)
            a.SetAtomMapNum(0)

    # set canonical ranks for atoms in env without maps
    m_env.UpdatePropertyCache()
    for atom_id, rank in zip(
        [a.GetIdx() for a in m_env.GetAtoms()], list(Chem.CanonicalRankAtoms(m_env)), strict=False
    ):
        a = m_env.GetAtomWithIdx(atom_id)
        if not a.HasProp(backup_atom_map):
            a.SetAtomMapNum(rank + 1)  # because ranks start from 0

    m = Chem.RWMol(Chem.CombineMols(m_frag, m_env))

    links = defaultdict(list)  # pairs of atom ids to create bonds
    att_to_remove = []  # ids of att points to remove
    for a in m.GetAtoms():
        if a.HasProp(backup_atom_map):
            i = a.GetIntProp(backup_atom_map)
            links[i].append(a.GetNeighbors()[0].GetIdx())
            att_to_remove.append(a.GetIdx())

    for i, j in links.values():
        m.AddBond(i, j, Chem.BondType.SINGLE)

    for i in sorted(att_to_remove, reverse=True):
        m.RemoveAtom(i)

    comb_sma = mol_to_smarts(m, keep_h)
    if not keep_h:  # remove H only in mapped env part
        comb_sma = patt_remove_h.sub("", comb_sma)
    return comb_sma
```

## File: src/crem/utils/utils.py
```python
import random
import sys
from collections import OrderedDict, defaultdict
from multiprocessing import cpu_count

import joblib
import numpy as np
from rdkit import Chem
from rdkit.Chem import rdMolDescriptors

# from crem.core.crem import _get_replacements, grow_mol2, mutate_mol2
from crem.core.operations import grow_mol2, mutate_mol2
from crem.core.replacement import _get_replacements


def __get_child_added_atom_ids(child_mol):
    """Returns ids of atoms in a current mol which were added upon grow/mutation procedure
    # After RDKit reaction procedure there is a field <react_atom_idx> with initial parent atom idx in a child mol
    """
    added_mol_ids = []
    for a in child_mol.GetAtoms():
        if not a.HasProp("react_atom_idx"):
            added_mol_ids.append(a.GetIdx())
    return sorted(added_mol_ids)


def __get_child_protected_atom_ids(mol, protected_parent_ids):
    """:param mol:
    :param protected_parent_ids: ids of a parent molecule which were protected and should be transferred to the
                                 current molecule
    :type  protected_parent_ids: list[int]
    :return: sorted list of integers
    """
    # After RDKit reaction procedure there is a field <react_atom_idx> with initial parent atom idx in product mol
    protected_mol_ids = []
    for a in mol.GetAtoms():
        if a.HasProp("react_atom_idx") and int(a.GetProp("react_atom_idx")) in protected_parent_ids:
            protected_mol_ids.append(a.GetIdx())
    return sorted(protected_mol_ids)


def __mol_with_atom_index(mol):
    atoms = mol.GetNumAtoms()
    for idx in range(atoms):
        mol.GetAtomWithIdx(idx).SetProp("molAtomMapNumber", str(mol.GetAtomWithIdx(idx).GetIdx()))
    return mol


def enumerate_compounds(
    mol,
    db_fname,
    mode="scaffold",
    n_iterations=1,
    radius=3,
    max_replacements=None,
    protected_ids=None,
    replace_ids=None,
    min_freq=0,
    protect_added_frag=False,
    return_smi=False,
    ncpu=None,
    **kwargs,
):
    """Convenience function to perform scaffold decoration or enumeration of analog series. This performs in multiple
    iterations by modification of compounds enumerated on the previous iteration. May result in combinatorial explosion.
    The function returns the list of distinct molecules generated over all iterations.

    Scaffold decoration uses grow procedure. Hydrogens will be added to the supplied molecule and replaced with
    fragments from the database. A user can protect particular positions from expansion by setting protect_ids argument.
    Note: The value of protect_added_frag parameter is ignored. New fragments cannot be attached to previously
    added fragments.

    Enumeration of analog series uses mutate procedure. The molecule should be supplied with explicit hydrogens if one
    wants to replace them as well, otherwise only heavy atoms will be considered for replacements. It is recommended to
    set an altered part of a molecule not too large to obtain reasonable suggestions.

    :param mol:
    :param db_fname: path to DB file with fragment replacements.
    :param mode: 'scaffold' decoration or 'analogs' enumeration. In 'scaffold' mode the supplied molecule will be
                 substituted with fragments from a database. In 'analogs' mode the supplied molecule wil be mutated.
                 Default: scaffold.
    :param n_iterations: the number of rounds of generation. Molecules generated on the previous round are supplied
                         to the next iteration. Be careful setting this parameter as it may cause combinatorial
                         explosion. Default: 1.
    :param radius: radius of context which will be considered for replacement. Default: 3.
    :param max_replacements: maximum number of replacements to make for each molecule on each iteration. None will
                             result in all possible replacements or it is possible to set a randomly chosen number of
                             replacements. Default: None.
    :param protected_ids: iterable with atom ids which will not be altered. In 'scaffold' mode this can be ids of
                          hydrogens or heavy atoms whose hydrogens should be protected from expansion. In 'analogs' mode
                          these are ids of hydrogens and heavy atoms. Please note, a molecule should be supplied with
                          explicit hydrogens in 'analogs' mode if one wants to replace them. Default: None.
    :param replace_ids: iterable with atom ids to replace, it has lower priority then `protected_ids`. Default: None.
    :param min_freq: minimum occurrence of fragments in DB for replacement. Default: 0.
    :param protect_added_frag: True or False. If set True new fragments cannot be attached/replace fragments added on
                               previous iterations. Applicable only in 'analogs' mode. In 'scaffold' mode user input is
                               ignored and the argument internally set to True. Default: False
    :param return_smi: if True will return the list of SMILES instead of Mol objects. Default: False.
    :param ncpu: number of cores. None means all cpus.

    :param kwargs: these arguments will be passed to grow_mol (for 'scaffold' mode) and mutate_mol ('analogs' mode)
    functions.

    arguments relevant to 'scaffold' mode
    min_atoms: minimum number of atoms in the fragment which will replace H
    max_atoms: maximum number of atoms in the fragment which will replace H

    arguments relevant to 'analogs' mode
    :min_size: minimum number of heavy atoms in a fragment to replace. If 0 - hydrogens will be replaced
                     (if they are explicit). Default: 0.
    :max_size: maximum number of heavy atoms in a fragment to replace. Default: 10.
    :min_inc: minimum change of a number of heavy atoms in replacing fragments to a number of heavy atoms in
                    replaced one. Negative value means that the replacing fragments would be smaller than the replaced
                    one on a specified number of heavy atoms. Default: -2.
    :max_inc: maximum change of a number of heavy atoms in replacing fragments to a number of heavy atoms in
                    replaced one. Default: 2.
    :replace_cycles: looking for replacement of a fragment containing cycles irrespectively of the fragment size.
                    Default: False.

    """
    if mode not in ["scaffold", "analogs"]:
        raise ValueError('Wrong mode. Please choose one from the list - "analogs","scaffold"')

    if ncpu is None:
        ncpu = cpu_count()
    else:
        ncpu = max(1, min(int(ncpu), cpu_count()))
    pool = joblib.Parallel(n_jobs=ncpu)

    # to check if the statical arguments are in the kwargs dict
    for kw in ["return_mol", "return_rxn", "return_rxn_freq", "ncores"]:
        if kw in kwargs:
            kwargs.pop(kw)

    if mode == "scaffold":
        protect_added_frag = True

    if protected_ids is None and replace_ids is not None:
        protected_ids = list(set(a.GetIdx() for a in mol.GetAtoms()).difference(replace_ids))
    if protected_ids is None:
        protected_ids = []

    start_mols = {mol: protected_ids}
    # to get results ordered by iterations
    generated_mols = OrderedDict()
    n = 0

    for n in range(n_iterations):
        new_mols = ()
        if mode == "scaffold":
            new_mols = pool(
                joblib.delayed(grow_mol2)(
                    m,
                    db_name=db_fname,
                    protected_ids=prot_ids,
                    min_freq=min_freq,
                    radius=radius,
                    max_replacements=max_replacements,
                    return_mol=True,
                    return_rxn=False,
                    return_rxn_freq=False,
                    ncores=1 if len(start_mols) > 1 else ncpu,
                    **kwargs,
                )
                for m, prot_ids in start_mols.items()
            )
        if mode == "analogs":
            new_mols = pool(
                joblib.delayed(mutate_mol2)(
                    m,
                    db_name=db_fname,
                    protected_ids=prot_ids,
                    min_freq=0,
                    radius=radius,
                    max_replacements=max_replacements,
                    return_mol=True,
                    return_rxn=False,
                    return_rxn_freq=False,
                    ncores=1 if len(start_mols) > 1 else ncpu,
                    **kwargs,
                )
                for m, prot_ids in start_mols.items()
            )

        parent_protected_ids_list = start_mols.values()
        start_mols = OrderedDict()
        for childs, parent_protected_ids in zip(new_mols, parent_protected_ids_list, strict=False):
            for items in childs:
                if items[0] not in generated_mols:
                    protected_ids = __get_child_protected_atom_ids(items[1], parent_protected_ids)
                    if protect_added_frag:
                        protect_added_ids = __get_child_added_atom_ids(items[1])
                        protected_ids = set(protected_ids + protect_added_ids)

                    generated_mols[items[0]] = items[1]
                    start_mols[items[1]] = protected_ids

        if not start_mols:
            break

    if n + 1 < n_iterations:
        sys.stderr.write(f"INFO. Procedure is finished after {n + 1} iterations instead of {n_iterations}\n")

    if not return_smi:
        return list(generated_mols.values())
    return list(generated_mols.keys())


def sample_csp3(row_ids, cur, radius, n):
    """Performs random selection of fragments proportionally to a squared fraction of sp3 carbon atoms.
    :param row_ids: the list of row ids of fragments to consider
    :param cur: cursor to the fragment database
    :param radius: context radius
    :param n: the number of fragments to select
    :return: the list of row ids of selected fragments
    """
    if n >= len(row_ids):
        return row_ids
    d = defaultdict(list)
    for rowid, core_smi, _, _ in _get_replacements(cur, radius, row_ids):
        d[core_smi].append(rowid)
    smis = list(d.keys())
    values = [rdMolDescriptors.CalcFractionCSP3(Chem.MolFromSmiles(smi)) ** 2 for smi in smis]
    values = [v + 0.01 for v in values]
    values = np.array(values) / sum(values)
    selected_smiles = np.random.choice(smis, n, replace=False, p=values).tolist()
    ids = []
    for smi in selected_smiles:
        ids.extend(d[smi])
    ids = random.sample(ids, n)
    return ids


def filter_max_ring_size(row_ids, cur, radius, max_size=6):
    """Remove fragments having a ring size greater than a maximum threshold value
    :param row_ids: the list of row ids of fragments to consider
    :param cur: cursor to the fragment database
    :param radius: context radius
    :param max_size: maximum allowed ring size
    :return: the list of row ids of selected fragments
    """
    d = defaultdict(list)
    for rowid, core_smi, _, _ in _get_replacements(cur, radius, row_ids):
        d[core_smi].append(rowid)
    smis = list(d.keys())
    for smi in smis:
        mol = Chem.MolFromSmiles(smi)
        w = mol.GetRingInfo()
        rings = w.AtomRings()
        if rings and max(len(atom_ids) for atom_ids in rings) > max_size:
            del d[smi]
    ids = []
    for v in d.values():
        ids.extend(v)
    return ids
```

## File: .gitignore
```
.idea
__pycache__
test_
crem.egg-info
build
dist
misc
pbs
reproducibility
bash
```

## File: .python-version
```
3.11
```

## File: .readthedocs.yml
```yaml
# .readthedocs.yml
version: 2

build:
  os: ubuntu-22.04
  tools:
    python: "3.11"
  jobs:
    pre_install:
      - pip install --upgrade pip
  steps:
    - install:
        # Install from requirements.txt
        # "doc" dependencies will be in there too (Sphinx, etc).
        commands:
          - pip install -r requirements.txt
    - build:
        commands:
          - sphinx-build -b html docs/source docs/build/html
```

## File: changelog
```
0.2.14

- add utils.filter_max_ring_size function implemementing fragment filtration
- add filter_func argument to all main functions to control fragment selection
- change the delta value used in sample_csp3

0.2.13

- add sample_func argument to control fragment sampling and biasing the selection
- add utils.sample_csp3 function implementing fragment selection biased by the fraction of sp3-carbon atoms

0.2.12

- add support of tab-delimited files with fragments and environments (useful if names/SMILES contain commas)

0.2.11

- add support of custom functions to filter fragments chosen for attachment/replacing
- add an example how to implement and use filtering function to README
- add an auxiliary function get_replacements

0.2.10

- fix to enable compatibility with python 3.11

0.2.9

- fix a lost molecule in output of grow and mutate

0.2.8

- add link to crem.imtm.cz to README
- change default separator in fragmentation.py to tab
- fix description of arguments for grow_mol
- fix output of molecules identical to the input structure

0.2.7

- add to mutate and grow functions treatment of topologically equivalent atoms

0.2.6

- add a module to enumerate compounds based on a seed molecules using scaffold or analog modes

0.2.5

- x2 code speed up
- fix pickling mol properties in multiprocessing
- add a tutorial on machine learning and CReM

0.2.4

- add support of custom parameters which can be used for fragment selection (**kwargs in mutate_mol, grow_mol, link_mols). A user can add custom parameters (e.g. pharmacophore features count, TPSA, etc) for each fragment in additional columns of a database and use these columns for fragment pre-filtering.

0.2.3

- fixed leakage of resources due to not closed pool in generators

0.2.2

- added jupyter notebook with examples
- fix mutate_mol generator for Python 3.7 and later

0.2.1

- fix link operation to return all possible links irrespectively to the order of linked molecules

0.2

- faster selection of random replacements
- added bash script crem_create_frag_db.sh to generate fragment database in one step
- fixed the RDKit bug which prevents fragmentation with three attachment points
```

## File: LICENSE.txt
```
BSD 3-Clause License

Copyright (c) 2018, Pavel Polishchuk
All rights reserved.

Redistribution and use in source and binary forms, with or without
modification, are permitted provided that the following conditions are met:

* Redistributions of source code must retain the above copyright notice, this
  list of conditions and the following disclaimer.

* Redistributions in binary form must reproduce the above copyright notice,
  this list of conditions and the following disclaimer in the documentation
  and/or other materials provided with the distribution.

* Neither the name of the copyright holder nor the names of its
  contributors may be used to endorse or promote products derived from
  this software without specific prior written permission.

THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
```

## File: pyproject.toml
```toml
[project]
name = "crem"
version = "0.2.14"
description = "CReM: chemically reasonable mutations framework"
readme = "README.md"
requires-python = ">=3.11"
license = "BSD-3-Clause"

# These dependencies mirror the older repo's requirements.txt
dependencies = [
    "m2r>=0.2",
    "sphinx>=5.0",
    "sphinx_rtd_theme>=1.0",
    "sphinxcontrib-applehelp>=1.0",
    "sphinxcontrib-devhelp>=1.0",
    "sphinxcontrib-htmlhelp>=2.0",
    "sphinxcontrib-jsmath>=1.0",
    "sphinxcontrib-qthelp>=1.0",
    "sphinxcontrib-serializinghtml>=1.0",
    "sphinxcontrib-programoutput>=0.18",
    "pandas>=2.2.3",
    "rdkit>=2024.3.6",
    "guacamol",
    "rich>=13.9.4",
    "snakeviz>=2.2.2",
    "line-profiler>=4.2.0",
]

# Define your console_scripts entry points here
[project.scripts]
fragmentation = "crem.cli.fragmentation:entry_point"
frag_to_env = "crem.cli.frag_to_env_mp:entry_point"
env_to_db = "crem.cli.import_env_to_db:entry_point"
guacamol_test = "crem.cli.guacamol_crem_test:entry_point"
crem_add_prop = "crem.cli.crem_add_prop:entry_point"

[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"

[tool.uv]
dev-dependencies = [
  "pyright>=1.1.389", 
  "ruff>=0.7.4"
]

[tool.uv.sources]
guacamol = { path = "../guacamol/dist/guacamol-0.5.5.tar.gz" }

[tool.ruff]
line-length = 120
target-version = "py312"
select = [
    "ALL", # include all the rules, including new ones
]
```

## File: README.md
```markdown
# CReM - chemically reasonable mutations

**CReM** is an open-source Python framework to generate chemical structures using a fragment-based approach.

The main idea behind is similar to matched molecular pairs considering context that fragments in the identical context are interchangeable. Therefore, one can create a database of interchangeable fragments and use it for generation of chemically valid structures.

**Features:**  
1) Generation of a custom fragment database  
2) Three modes of structure generation: MUTATE, GROW, LINK  
3) Context radius to consider for replacement  
4) Fragment size to replace and the size of a replacing fragment  
5) Protection of atoms from modification (e.g. scaffold protection)  
6) Replacements with fragments occurred in a fragment database with certain minimal frequency  
7) Make randomly chosen replacements up to the specified number  

**Limitations and known issues**
1) New ring systems cannot be constructed from fragments, thus representativeness of ring systems in generated structures depends on a used fragment database. We are working on that issue.
2) Very large molecules will not be processed by CReM. If a molecule has more than 30 non-ring single bonds it will not be MUTATED. If a molecule has more than 100 hydrogen atoms it will not be processed by GROW and LINK.
3) Canonicalisation of contexts depends on RDKit SMILES representation. Thus, changing in RDKit SMILES representation may affect fragment databases and make impossible to use a database prepared with previous RDKit version from code running under later RDKit versions.  

## Documentation

https://crem.readthedocs.io/en/latest/

## Web app

To play with a tool online.  
https://crem.imtm.cz/

## Installation

Several command line utilities will be installed to create fragment databases and `crem` module will become available in Python imports to generate structures.

From pypi package
```text
pip install crem
```

Manually from repository
```text
git clone https://github.com/DrrDom/crem
cd crem
python3 setup.py sdist bdist_wheel
pip install dist/crem-0.1-py3-none-any.whl
```

Uninstall
```text
pip uninstall crem
```

## Dependencies

`crem` requires `rdkit>=2017.09`. To run the guacamol test `guacamol` should be installed.

## Generation of a fragment database

This step is required if you want to generate a custom fragment database. You can download precompiled databases obtained by fragmentation of the whole ChEMBL by links provided on this page - http://www.qsar4u.com/pages/crem.php.  

For convenience there is the bash script crem_create_frag_db.sh which includes all steps below. It takes three positional arguments: input file with SMILES, output directory where intermediate files and a final database will be stored and number of CPUs to use (this is optional, default value is 1).
```text
crem_create_frag_db.sh input.smi fragdb_dir 32
```
 
Fragmentation of input structures:
```text
fragmentation -i input.smi -o frags.txt -c 32 -v
```

Convert fragments to standardized representation of a core and a context of a given radius:
```text
frag_to_env -i frags.txt -o r3.txt -r 3 -c 32 -v
```

Remove duplicated lines in the output file and count frequency of occurrence of fragemnt-context pairs. These (`sort` and `uniq`) are `bash` utilities but since Win10 is Linux-friendly that should not be a big issue for Win users to execute them
```text
sort r3.txt | uniq -c > r3_c.txt
```

Create DB and import the file to a database table
```text
env_to_db -i r3_c.txt -o fragments.db -r 3 -c -v
```

Last three steps should be executed for each radius. All tables can be stored in the same database.

```bash
python guacamol_crem_test.py \
    --smiles_file /Users/thomasgraham/prj/crem/example/CHEMBL231.smi \
    --db_fname /Users/thomasgraham/prj/crem/output_uv/fragments.db \
    --selection_size 50 \
    --radius 3 \
    --replacements 1000 \
    --min_size 0 \
    --max_size 10 \
    --min_inc -10 \
    --max_inc 10 \
    --generations 1000 \
    --ncpu 10 \
    --seed 42 \
    --output_dir /path/to/output \
    --suite v2 \
    --log_level DEBUG
```

## Structure generation

Import necessary functions from the main module
```python
from crem.crem import mutate_mol, grow_mol, link_mols
from rdkit import Chem
```

Create a molecute and **mutate** it. Only one heavy atom will be substituted. Default radius is 3.
```python
m = Chem.MolFromSmiles('c1cc(OC)ccc1C')  # methoxytoluene
mols = list(mutate_mol(m, db_name='replacements.db', max_size=1))
```
output example
```text
['CCc1ccc(C)cc1',
 'CC#Cc1ccc(C)cc1',
 'C=C(C)c1ccc(C)cc1',
 'CCCc1ccc(C)cc1',
 'CC=Cc1ccc(C)cc1',
 'CCCCc1ccc(C)cc1',
 'CCCOc1ccc(C)cc1',
 'CNCCc1ccc(C)cc1',
 'COCCc1ccc(C)cc1',
 ...
 'Cc1ccc(C(C)(C)C)cc1']
```


Add hydrogens to the molecule to **mutate hydrogens** as well
```python
mols = list(mutate_mol(Chem.AddHs(m), db_name='replacements.db', max_size=1))
```
output
```text
['CCc1ccc(C)cc1',
 'CC#Cc1ccc(C)cc1',
 'C=C(C)c1ccc(C)cc1',
 'CCCc1ccc(C)cc1',
 'Cc1ccc(C(C)C)cc1',
 'CC=Cc1ccc(C)cc1',
 ...
 'COc1ccc(C)cc1C',
 'C=Cc1cc(C)ccc1OC',
 'COc1ccc(C)cc1Cl',
 'COc1ccc(C)cc1CCl']
```

**Grow** molecule. Only hydrogens will be replaced. Hydrogens should not be added explicitly.
```python
mols = list(grow_mol(m, db_name='replacements.db'))
```
output
```text
['COc1ccc(C)c(Br)c1',
 'COc1ccc(C)c(C)c1',
 'COc1ccc(C)c(Cl)c1',
 'COc1ccc(C)c(OC)c1',
 'COc1ccc(C)c(N)c1',
 ...
 'COc1ccc(CCN)cc1']
```

Create the second molecule and **link** it to toluene
```python
m2 = Chem.MolFromSmiles('NCC(=O)O')  # glycine
mols = list(link_mols(m, m2, db_name='replacements.db'))
```
output
```text
['Cc1ccc(OCC(=O)NCC(=O)O)cc1',
 'Cc1ccc(OCCOC(=O)CN)cc1',
 'COc1ccc(CC(=N)NCC(=O)O)cc1',
 'COc1ccc(CC(=O)NCC(=O)O)cc1',
 'COc1ccc(CC(=S)NCC(=O)O)cc1',
 'COc1ccc(CCOC(=O)CN)cc1']
```

You can vary the size of a linker and specify the distance between two attachment points in a linking fragment. There are many other arguments available in these functions, look at their **docstrings** for details.

##### Additional filters to control fragments chosen for replacing

An example of a filtering function which will keep only fragments containing a specific atom to be chosen for replacing.

```python
from collections import defaultdict
from functools import partial
from rdkit import Chem

def filter_function(row_ids, cur, radius, atom_number):

    """
    The first three arguments should be always the same as shown in the example. These parameters will be passed to a function from a main function, e.g. from mutate_mol. All other arguments are user-defined. The function should return the list of row ids of fragments which will be used for replacing. 

    :param row_id: a list of row ids from CReM database of those fragments which satisfy other selection criteria
    :param cur: cursor of CReM database
    :param radius: radius of a context 
    :param atom_number: an atomic number, fragments with this number will be discarded
    :return list of remaining row ids
    """

    # this part may be kept intact, it collects from DB SMILES of fragments with given row ids
    # since fragments may occur multiple times (due to different contexts) the results are collected in a dict
    if not row_ids:
        return []
    batch_size = 32000  # SQLite has a limit on a number of passed values to a query
    row_ids = list(row_ids)
    smis = defaultdict(list)  # {smi_1: [rowid_1, rowid_5, ...], ...}
    for start in range(0, len(row_ids), batch_size):
        batch = row_ids[start:start + batch_size]
        sql = f"SELECT rowid, core_smi FROM radius{radius} WHERE rowid IN ({','.join('?' * len(batch))})"
        for i, smi in cur.execute(sql, batch).fetchall():
            smis[smi].append(i)

    output_row_ids = []
    for smi, ids in smis.items():
        for a in Chem.MolFromSmiles(smi).GetAtoms():
            if a.GetAtomicNum() == atom_number:
                output_row_ids.extend(ids)
    return output_row_ids

# only F-containing fragments will be chosen for replacing
mol = Chem.MolFromSmiles('c1ccccc1C')
mols = mutate_mol(mol, db_name='replacements.db', filter_func=partial(filter_function, atom_number=9), max_size=1, max_inc=3)
```
output
```text
['Fc1ccccc1', 
 'FC(F)(F)c1ccccc1',
 'FC(F)Oc1ccccc1',
 'FC(F)Sc1ccccc1']
```

##### Custom sampling of randomly chosen fragments

If not all possible derivatives are necessary to generate a user may limit the number of returned compounds by `max_replacements` argument which enable uniform sampling of a desired number of molecules. To enable custom sampling and bias selection to more desired chemotypes there is an argument `sample_func` which takes a function implementing the selection. This function should take four necessary arguments: row_ids (list or set of row_ids from the fragment database), cursor of that fragment database, radius (int) and the number of returned items (int). An example of such a function is implemented in `utils` module and showed below. Other biases can be introduced via this option. Please not, using of complex sampling functions may slow down structure generation.
```python
def sample_csp3(row_ids, cur, radius, n):
    """
    Performs random selection of fragments proportionally to a squared fraction of sp3 carbon atoms.
    :param row_ids: the list of row ids of fragments to consider
    :param cur: cursor to the fragment database
    :param radius: context radius
    :param n: the number of fragments to select
    :return: the list of row ids of selected fragments
    """
    d = defaultdict(list)
    for rowid, core_smi, _, _ in _get_replacements(cur, radius, row_ids):
        d[core_smi].append(rowid)
    smis = list(d.keys())
    values = [rdMolDescriptors.CalcFractionCSP3(Chem.MolFromSmiles(smi)) ** 2 for smi in smis]
    values = [v + 1e-8 for v in values]
    values = np.array(values) / sum(values)
    selected_smiles = np.random.choice(smis, n, replace=False, p=values).tolist()
    ids = []
    for smi in selected_smiles:
        ids.extend(d[smi])
    ids = random.sample(ids, n)
    return ids
```
Example of `sample_func` application. F atom is replaced and 10 derivatives is returned biased by the fraction of sp3 carbons and not.
```python
m = Chem.MolFromSmiles('c1ccccc1F')

res = list(mutate_mol(m, 'replacements_sa2_f5.db',
                      radius=3, min_inc=0, max_inc=10, max_replacements=10,
                      replace_ids=[6]))
values = sorted(round(rdMolDescriptors.CalcFractionCSP3(Chem.MolFromSmiles(smi)), 4) for smi in res)
print(res)
print(values)

res = list(mutate_mol(m, 'replacements_sa2_f5.db',
                      radius=3, min_inc=0, max_inc=10, max_replacements=10,
                      replace_ids=[6], sample_func=sample_csp3))
values = sorted(round(rdMolDescriptors.CalcFractionCSP3(Chem.MolFromSmiles(smi)), 4) for smi in res)
print(res)
print(values)
```
output
```text
# uniform sampling
['c1ccc(-c2ccc(-c3csnn3)cc2)cc1', 'c1ccc(COc2cccnc2)cc1', 'CCCc1ccc(OCc2ccccc2)cc1', 'CC(C)(O)C(=O)NCCc1ccccc1', 'CN(C)C(=O)CNC(=O)OCc1ccccc1', 'COc1ccc(-c2ccccc2)cc1C(N)=O', 'Fc1ccccc1-c1ccccc1', 'Nc1cccnc1Sc1ccccc1', 'O=C(Nc1ccc(F)c(F)c1)c1ccccc1', 'O=C(COC(=O)c1ccco1)c1ccccc1']
[0.0, 0.0, 0.0, 0.0, 0.0714, 0.0769, 0.0833, 0.25, 0.3333, 0.4167]

# sampling biased by the fraction of sp3 carbons
['c1ccc(CNCc2ccncc2)cc1', 'Cc1cccc(CSc2ccccc2)n1', 'CC(=Cc1ccccc1)CN1CCN(C)CC1', 'CC(C)N(CCOc1ccccc1)C(C)C', 'CCN(CCC#N)C(=O)Nc1ccccc1', 'CSCc1ccccc1', 'O=C(Cc1ccccc1)NCCc1ccoc1', 'O=C(CCc1ccccc1)NC1CCCCC1', 'O=C(CN1CCCC1)NCCc1ccccc1', 'O=C(CSc1ccccc1)NC1CC1']
[0.1538, 0.1538, 0.2143, 0.25, 0.3333, 0.3636, 0.4667, 0.5, 0.5333, 0.5714]
```
In the latter case there are molecules having the greater fraction of sp3-carbon atoms.


##### Iterative enumeration

For convenience there is a function `enumerate_compounds` in `utils` module (added in version 0.2.6). It performs iterative growing (scaffold decoration) or mutation (analog enumeration) of a supplied molecule. More details are in docstring of the function.

Example. Enumerate derivatives of 1-chloro-3-methylbenzene at positions 2 and 4 of the ring and at the methyl group at the same time. In this case one should choose `scaffold` mode, 3 iterations, specify atom ids (0-based indices) where fragments can be attached and set `protect_added_frag=True` to restrict enumeration only to selected positions.

```python
from crem.utils import enumerate_compounds

mol = Chem.MolFromMolBlock("""
  Mrv1922 05242309182D          

  8  8  0  0  0  0            999 V2000
   -3.2813    1.3161    0.0000 C   0  0  0  0  0  0  0  0  0  0  0  0
   -3.9957    0.9036    0.0000 C   0  0  0  0  0  0  0  0  0  0  0  0
   -3.9957    0.0786    0.0000 C   0  0  0  0  0  0  0  0  0  0  0  0
   -3.2813   -0.3339    0.0000 C   0  0  0  0  0  0  0  0  0  0  0  0
   -2.5668    0.0786    0.0000 C   0  0  0  0  0  0  0  0  0  0  0  0
   -2.5668    0.9036    0.0000 C   0  0  0  0  0  0  0  0  0  0  0  0
   -3.2813   -1.1589    0.0000 C   0  0  0  0  0  0  0  0  0  0  0  0
   -1.8523    1.3161    0.0000 Cl  0  0  0  0  0  0  0  0  0  0  0  0
  1  2  1  0  0  0  0
  2  3  2  0  0  0  0
  3  4  1  0  0  0  0
  4  5  2  0  0  0  0
  5  6  1  0  0  0  0
  1  6  2  0  0  0  0
  4  7  1  0  0  0  0
  6  8  1  0  0  0  0
M  END
""")

mols = enumerate_compounds(mol, 'replacements_sa2.db', mode='scaffold', n_iterations=3,
                           radius=3, max_replacements=2, replace_ids=[2,4,6], protect_added_frag=True, 
                           return_smi=True)
``` 
output
```
['COc1c(C)cccc1Cl', 
'Cc1cc(Cl)ccc1Cl', 
'COc1ccc(Cl)c(OC)c1C', 
'COc1c(Cl)cccc1CF', 
'Cc1c(Cl)ccc(Cl)c1C', 
'CSCc1cc(Cl)ccc1Cl', 
'COc1ccc(Cl)c(OC)c1CC#N', 
'COCc1c(OC)ccc(Cl)c1OC', 
'COc1c(Cl)cccc1C(F)F', 
'COc1c(Cl)ccc(CO)c1CF', 
'Cc1c(Cl)ccc(Cl)c1CC#N', 
'Cc1c(Cl)ccc(Cl)c1CCN', 
'CSCc1c(Cl)ccc(Cl)c1C', 
'CSCc1c(Cl)ccc(Cl)c1Cl']
```

##### Multiprocessing
All functions have an argument `ncores` and can make mupltile replacement in one molecule in parallel. If you want to process several molecules in parallel you have to write your own code. However, the described functions are generators and cannot be used with `multiprocessing` module. Therefore, three complementary functions `mutate_mol2`, `grow_mol2` and `link_mols2` were created. They return the list with results and can be pickled and used with `multiprocessing.Pool` or other tools.

Example:
```python
from multiprocessing import Pool
from functools import partial
from crem.crem import mutate_mol2
from rdkit import Chem

p = Pool(2)
input_smi = ['c1ccccc1N', 'NCC(=O)OC', 'NCCCO']
input_mols = [Chem.MolFromSmiles(s) for s in input_smi]

res = list(p.imap(partial(mutate_mol2, db_name='replacements.db', max_size=1), input_mols))
```

`res` would be a list of lists with SMILES of generated molecules

## Bechmarks

##### Guacamol

|task|SMILES LSTM*|SMILES GA*|Graph GA*|Graph MCTS*|CReM
|---|:---:|:---:|:---:|:---:|:---:|
|Celecoxib rediscovery|**1.000**|0.732|**1.000**|0.355|**1.000**
|Troglitazone rediscovery|**1.000**|0.515|**1.000**|0.311|**1.000**
|Thiothixene rediscovery|**1.000**|0.598|**1.000**|0.311|**1.000**
|Aripiprazole similarity|**1.000**|0.834|**1.000**|0.380|**1.000**
|Albuterol similarity|**1.000**|0.907|**1.000**|0.749|**1.000**
|Mestranol similarity|**1.000**|0.79|**1.000**|0.402|**1.000**
|C11H24|**0.993**|0.829|0.971|0.410|0.966
|C9H10N2O2PF2Cl|0.879|0.889|**0.982**|0.631|0.940
|Median molecules 1|**0.438**|0.334|0.406|0.225|0.371
|Median molecules 2|0.422|0.38|0.432|0.170|**0.434**
|Osimertinib MPO|0.907|0.886|0.953|0.784|**0.995**
|Fexofenadine MPO|0.959|0.931|0.998|0.695|**1.000**
|Ranolazine MPO|0.855|0.881|0.92|0.616|**0.969**
|Perindopril MPO|0.808|0.661|0.792|0.385|**0.815**
|Amlodipine MPO|0.894|0.722|0.894|0.533|**0.902**
|Sitagliptin MPO|0.545|0.689|**0.891**|0.458|0.763
|Zaleplon MPO|0.669|0.413|0.754|0.488|**0.770**
|Valsartan SMARTS|0.978|0.552|0.990|0.04|**0.994**
|Deco Hop|0.996|0.970|**1.000**|0.590|**1.000**
|Scaffold Hop|0.998|0.885|**1.000**|0.478|**1.000**
|total score|17.341|14.398|17.983|9.011|17.919

## License
BSD-3

## Citation
CReM: chemically reasonable mutations framework for structure generation    
Pavel Polishchuk  
*Journal of Cheminformatics* **2020**, 12, (1), 28  
https://doi.org/10.1186/s13321-020-00431-w

Control of Synthetic Feasibility of Compounds Generated with CReM  
Pavel Polishchuk  
*Journal of Chemical Information and Modeling* **2020**, 60, 6074-6080  
https://dx.doi.org/10.1021/acs.jcim.0c00792
```

## File: repomix.sh
```bash
#!/bin/bash
npx repomix --ignore "profile*,test/,src/crem/core/cremold.py,uv.lock,example/,db_output/,requirements.old.txt,output_uv/" --style markdown
```
